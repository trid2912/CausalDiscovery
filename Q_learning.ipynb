{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from math import log\n",
        "class BaseEstimator(object):\n",
        "    \"\"\"\n",
        "    Base class for estimators in pgmpy; `ParameterEstimator`,\n",
        "    `StructureEstimator` and `StructureScore` derive from this class.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: pandas DataFrame object\n",
        "        object where each column represents one variable.\n",
        "        (If some values in the data are missing the data cells should be set to `numpy.NaN`.\n",
        "        Note that pandas converts each column containing `numpy.NaN`s to dtype `float`.)\n",
        "\n",
        "    state_names: dict (optional)\n",
        "        A dict indicating, for each variable, the discrete set of states (or values)\n",
        "        that the variable can take. If unspecified, the observed values in the data set\n",
        "        are taken to be the only possible states.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data=None, state_names=None):\n",
        "        self.data = data\n",
        "        # data can be None in the case when learning structure from\n",
        "        # independence conditions. Look into PC.py.\n",
        "        if self.data is not None:\n",
        "            self.variables = list(data.columns.values)\n",
        "\n",
        "            if not isinstance(state_names, dict):\n",
        "                self.state_names = {\n",
        "                    var: self._collect_state_names(var) for var in self.variables\n",
        "                }\n",
        "            else:\n",
        "                self.state_names = dict()\n",
        "                for var in self.variables:\n",
        "                    if var in state_names:\n",
        "                        if not set(self._collect_state_names(var)) <= set(\n",
        "                            state_names[var]\n",
        "                        ):\n",
        "                            raise ValueError(\n",
        "                                f\"Data contains unexpected states for variable: {var}.\"\n",
        "                            )\n",
        "                        self.state_names[var] = state_names[var]\n",
        "                    else:\n",
        "                        self.state_names[var] = self._collect_state_names(var)\n",
        "\n",
        "    def _collect_state_names(self, variable):\n",
        "        \"Return a list of states that the variable takes in the data.\"\n",
        "        states = sorted(list(self.data.loc[:, variable].dropna().unique()))\n",
        "        return states\n",
        "\n",
        "    def state_counts(\n",
        "        self,\n",
        "        variable,\n",
        "        parents=[],\n",
        "        weighted=False,\n",
        "        reindex=True,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Return counts how often each state of 'variable' occurred in the data.\n",
        "        If a list of parents is provided, counting is done conditionally\n",
        "        for each state configuration of the parents.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        variable: string\n",
        "            Name of the variable for which the state count is to be done.\n",
        "\n",
        "        parents: list\n",
        "            Optional list of variable parents, if conditional counting is desired.\n",
        "            Order of parents in list is reflected in the returned DataFrame\n",
        "\n",
        "        weighted: bool\n",
        "            If True, data must have a `_weight` column specifying the weight of the\n",
        "            datapoint (row). If False, each datapoint has a weight of `1`.\n",
        "\n",
        "        reindex: bool\n",
        "            If True, returns a data frame with all possible parents state combinations\n",
        "            as the columns. If False, drops the state combinations which are not\n",
        "            present in the data.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        state_counts: pandas.DataFrame\n",
        "            Table with state counts for 'variable'\n",
        "\n",
        "        Examples\n",
        "        --------\n",
        "        >>> import pandas as pd\n",
        "        >>> from pgmpy.estimators import BaseEstimator\n",
        "        >>> data = pd.DataFrame(data={'A': ['a1', 'a1', 'a2'],\n",
        "                                      'B': ['b1', 'b2', 'b1'],\n",
        "                                      'C': ['c1', 'c1', 'c2']})\n",
        "        >>> estimator = BaseEstimator(data)\n",
        "        >>> estimator.state_counts('A')\n",
        "            A\n",
        "        a1  2\n",
        "        a2  1\n",
        "        >>> estimator.state_counts('C', parents=['A', 'B'])\n",
        "        A  a1      a2\n",
        "        B  b1  b2  b1  b2\n",
        "        C\n",
        "        c1  1   1   0   0\n",
        "        c2  0   0   1   0\n",
        "        >>> estimator.state_counts('C', parents=['A'])\n",
        "        A    a1   a2\n",
        "        C\n",
        "        c1  2.0  0.0\n",
        "        c2  0.0  1.0\n",
        "        \"\"\"\n",
        "        parents = list(parents)\n",
        "\n",
        "        if weighted and (\"_weight\" not in self.data.columns):\n",
        "            raise ValueError(\"data must contain a `_weight` column if weighted=True\")\n",
        "\n",
        "        if not parents:\n",
        "            # count how often each state of 'variable' occurred\n",
        "            if weighted:\n",
        "                state_count_data = self.data.groupby([variable])[\"_weight\"].sum()\n",
        "            else:\n",
        "                state_count_data = self.data.loc[:, variable].value_counts()\n",
        "\n",
        "            state_counts = (\n",
        "                state_count_data.reindex(self.state_names[variable])\n",
        "                .fillna(0)\n",
        "                .to_frame()\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            parents_states = [self.state_names[parent] for parent in parents]\n",
        "            # count how often each state of 'variable' occurred, conditional on parents' states\n",
        "            if weighted:\n",
        "              state_count_data = (\n",
        "                  self.data.groupby([variable] + parents)[\"_weight\"]\n",
        "                  .sum()\n",
        "                  .unstack(parents)\n",
        "              )\n",
        "\n",
        "\n",
        "            else:\n",
        "              state_count_data = (\n",
        "                  self.data.groupby([variable] + parents).size().unstack(parents)\n",
        "              )\n",
        "\n",
        "            if not isinstance(state_count_data.columns, pd.MultiIndex):\n",
        "              state_count_data.columns = pd.MultiIndex.from_arrays(\n",
        "                  [state_count_data.columns]\n",
        "              )\n",
        "\n",
        "            if reindex:\n",
        "              # reindex rows & columns to sort them and to add missing ones\n",
        "              # missing row    = some state of 'variable' did not occur in data\n",
        "              # missing column = some state configuration of current 'variable's parents\n",
        "              #                  did not occur in data\n",
        "              row_index = self.state_names[variable]\n",
        "              column_index = pd.MultiIndex.from_product(parents_states, names=parents)\n",
        "              state_counts = state_count_data.reindex(\n",
        "                  index=row_index, columns=column_index\n",
        "              ).fillna(0)\n",
        "            else:\n",
        "              state_counts = state_count_data.fillna(0)\n",
        "\n",
        "        return state_counts\n",
        "    def local_score(self, variable, parents):\n",
        "        'Computes a score that measures how much a \\\n",
        "        given variable is \"influenced\" by a given list of potential parents.'\n",
        "\n",
        "        var_states = self.state_names[variable]\n",
        "        var_cardinality = len(var_states)\n",
        "        parents = list(parents)\n",
        "        state_counts = self.state_counts(variable, parents, reindex=False)\n",
        "        sample_size = len(self.data)\n",
        "        num_parents_states = np.prod([len(self.state_names[var]) for var in parents])\n",
        "\n",
        "        counts = np.asarray(state_counts)\n",
        "        log_likelihoods = np.zeros_like(counts, dtype=float)\n",
        "        # Compute the log-counts\n",
        "        np.log(counts, out=log_likelihoods, where=counts > 0)\n",
        "        # Compute the log-conditional sample size\n",
        "        log_conditionals = np.sum(counts, axis=0, dtype=float)\n",
        "        np.log(log_conditionals, out=log_conditionals, where=log_conditionals > 0)\n",
        "        # Compute the log-likelihoods\n",
        "        log_likelihoods -= log_conditionals\n",
        "        log_likelihoods *= counts\n",
        "\n",
        "        score = np.sum(log_likelihoods)\n",
        "\n",
        "        score -= 0.5 * log(sample_size) * num_parents_states * (var_cardinality - 1)\n",
        "\n",
        "        return score\n"
      ],
      "metadata": {
        "id": "XaIHV-NTCrld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da3ef01-16e6-4bde-c949-983cbb734163"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_dag(adjacency_matrix):\n",
        "  \"\"\"Checks if an adjacency matrix is nilpotent.\n",
        "\n",
        "  Args:\n",
        "    adjacency_matrix: A numpy array representing the adjacency matrix.\n",
        "\n",
        "  Returns:\n",
        "    True if the adjacency matrix is nilpotent, False otherwise.\n",
        "  \"\"\"\n",
        "\n",
        "  for i in range(len(adjacency_matrix)):\n",
        "    power = np.linalg.matrix_power(adjacency_matrix, i + 1)\n",
        "    if np.trace(power) != 0:\n",
        "      return False\n",
        "\n",
        "  return True\n",
        "\n",
        "def calculate_bic_score(graph, base_estimate):\n",
        "  nodes = list(base_estimate.state_names.keys())\n",
        "\n",
        "  num_nodes = len(nodes)\n",
        "  bic_score = 0\n",
        "  for k in range(num_nodes):\n",
        "    parents = np.nonzero(graph[:,k])[0]\n",
        "    parents = [nodes[k] for k in parents]\n",
        "    if nodes[k] in parents:\n",
        "      parents.remove(nodes[k])\n",
        "    bic_score += base_estimate.local_score(nodes[k], parents)\n",
        "  return bic_score"
      ],
      "metadata": {
        "id": "DTZnhaDREFvv"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Asia.csv\")\n",
        "data = data.drop('Unnamed: 0', axis=1)\n",
        "base_estimate = BaseEstimator(data)\n",
        "graph = np.array([[0, 0, 0, 0, 0, 0, 0, 0],[0., 0., 0., 1., 0., 0., 0., 0.], [0., 0., 0., 0., 1., 1., 0., 1.], [0., 0., 0., 0., 0., 1., 0., 0.],\n",
        " [0., 1., 0., 1., 0., 0., 0., 0.],[0., 0., 0., 0., 0., 0., 1., 0.],[0., 0., 0., 0., 0., 0., 0., 0.], [0., 1., 0., 1., 1., 0., 0., 0.]])\n",
        "\n",
        "print(calculate_bic_score(graph, base_estimate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqHLQUcaGR6r",
        "outputId": "ede92f9b-ad0a-4d04-ed88-3b3ba7e1156d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-11141.386647046336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "kgmgEtzJBF47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a956b5-c0da-4826-e4f4-10e5ed67ad2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "# Define the Gym environment for the causal graph problem\n",
        "class CausalGraphEnv(gym.Env):\n",
        "    def __init__(self, n):\n",
        "        super(CausalGraphEnv, self).__init__()\n",
        "        self.n = n\n",
        "        self.action_space = spaces.Discrete(n * n * 2)  # Two actions for each element in the matrix\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(n, n), dtype=np.uint8)\n",
        "        self.min_bic = 99999999\n",
        "        self.best_state = np.zeros((self.n, self.n), dtype=np.uint8)\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.zeros((self.n, self.n), dtype=np.uint8)\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action, base_estimate):\n",
        "        print(\"actions: \", action)\n",
        "        i, j = divmod(action // 2, self.n)  # Determine the matrix element to change\n",
        "        toggle = action % 2  # Determine whether to set or unset the edge\n",
        "\n",
        "        # Save the current state to revert back if the action is invalid\n",
        "        original_state = np.copy(self.state)\n",
        "        # Apply the action\n",
        "        self.state[i, j] = 1-self.state[i,j] if toggle == 1 else 0\n",
        "\n",
        "        if is_dag(self.state):\n",
        "            # Calculate the BIC score and determine the reward\n",
        "            new_bic_score = calculate_bic_score(self.state, base_estimate)\n",
        "            bic_score = - new_bic_score  # Reward is the negative BIC score\n",
        "            done = False  # We can define the termination condition based on the problem\n",
        "        else:\n",
        "            # Revert to the original state as the action results in a non-DAG\n",
        "            self.state = original_state\n",
        "            bic_score = -1  # Penalize the action that results in a non-DAG\n",
        "            done = True  # Optionally end the episode\n",
        "        if bic_score < self.min_bic and bic_score > 0:\n",
        "            self.best_state = np.copy(self.state)\n",
        "            self.min_bic = bic_score\n",
        "        return self.state, bic_score, done, {}\n",
        "\n",
        "    def render(self, mode='console'):\n",
        "        if mode != 'console':\n",
        "            raise NotImplementedError()\n",
        "        print(self.state)\n",
        "    def result(self):\n",
        "        return self.best_state\n",
        "\n",
        "# Define the Q-network using PyTorch\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, n):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(n * n, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, n * n * 2)  # Output size: n*n*2 (for each element in the matrix, two possible actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.5\n",
        "class QLearningAgent:\n",
        "    def __init__(self, env, q_network):\n",
        "        self.env = env\n",
        "        self.q_network = q_network\n",
        "        self.optimizer = optim.Adam(q_network.parameters(), lr=0.001)\n",
        "\n",
        "    def train(self,base_estimate, episodes=1000, gamma=0.99):\n",
        "        for episode in range(episodes):\n",
        "            state = self.env.reset()\n",
        "            total_reward = 0\n",
        "            done = False\n",
        "            while not done:\n",
        "\n",
        "                # Convert state to tensor for PyTorch\n",
        "                state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
        "\n",
        "                # Epsilon-greedy strategy for action selection\n",
        "                if random.random() < epsilon:\n",
        "                    action = self.env.action_space.sample()\n",
        "                else:\n",
        "                    q_values = self.q_network(state_tensor)\n",
        "                    action = torch.argmax(q_values).item()\n",
        "\n",
        "                # Take action and observe new state and reward\n",
        "                new_state, bic_score, done, _ = self.env.step(action, base_estimate)\n",
        "\n",
        "                # Calculate BIC score based change as reward\n",
        "                old_bic_score = calculate_bic_score(state, base_estimate)\n",
        "                new_bic_score = calculate_bic_score(new_state, base_estimate)\n",
        "\n",
        "                reward =  new_bic_score - old_bic_score\n",
        "                # Convert new state to tensor\n",
        "                new_state_tensor = torch.FloatTensor(new_state).unsqueeze(0)\n",
        "\n",
        "                # Calculate target Q-value\n",
        "                target_q_value = reward + gamma * torch.max(self.q_network(new_state_tensor)).item()\n",
        "                target_q_value = torch.tensor(target_q_value, dtype = torch.float)\n",
        "                # Get current Q-value\n",
        "\n",
        "                current_q_value = self.q_network(state_tensor)[action]\n",
        "                #print(nn.functional.mse_loss(float(current_q_value), target_q_value))\n",
        "                # Calculate loss\n",
        "                print(\"Current_q_value\", current_q_value)\n",
        "                loss = nn.functional.mse_loss(current_q_value, target_q_value)\n",
        "\n",
        "\n",
        "                # Backpropagation\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                state = np.copy(new_state)\n",
        "                total_reward += reward\n",
        "\n",
        "            print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
        "\n",
        "# Example usage\n",
        "env = CausalGraphEnv(n=8)\n",
        "q_network = QNetwork(n=8)\n",
        "agent = QLearningAgent(env, q_network)\n",
        "agent.train(base_estimate ,episodes=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XovaNDWsBPRh",
        "outputId": "7f5dbea7-9c59-4fe3-9a70-7c9fdee3c9a5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actions:  119\n",
            "Current_q_value tensor(0.2478, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2753, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.1916, grad_fn=<SelectBackward0>)\n",
            "actions:  109\n",
            "Current_q_value tensor(0.1389, grad_fn=<SelectBackward0>)\n",
            "Episode 0, Total Reward: -81.8364848624733\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.1335, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2608, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(0.1571, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2644, grad_fn=<SelectBackward0>)\n",
            "actions:  62\n",
            "Current_q_value tensor(-0.1208, grad_fn=<SelectBackward0>)\n",
            "actions:  66\n",
            "Current_q_value tensor(0.1173, grad_fn=<SelectBackward0>)\n",
            "actions:  116\n",
            "Current_q_value tensor(-0.1893, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2632, grad_fn=<SelectBackward0>)\n",
            "actions:  74\n",
            "Current_q_value tensor(-0.2260, grad_fn=<SelectBackward0>)\n",
            "actions:  59\n",
            "Current_q_value tensor(0.0757, grad_fn=<SelectBackward0>)\n",
            "actions:  85\n",
            "Current_q_value tensor(-0.0541, grad_fn=<SelectBackward0>)\n",
            "actions:  78\n",
            "Current_q_value tensor(0.0510, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2866, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2859, grad_fn=<SelectBackward0>)\n",
            "actions:  55\n",
            "Current_q_value tensor(0.0414, grad_fn=<SelectBackward0>)\n",
            "Episode 1, Total Reward: 1279.5090614910787\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2442, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2350, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(-0.0084, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2436, grad_fn=<SelectBackward0>)\n",
            "actions:  49\n",
            "Current_q_value tensor(-0.0306, grad_fn=<SelectBackward0>)\n",
            "actions:  6\n",
            "Current_q_value tensor(0.1443, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(-0.0126, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2353, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2447, grad_fn=<SelectBackward0>)\n",
            "actions:  86\n",
            "Current_q_value tensor(-0.1622, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(0.1937, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2307, grad_fn=<SelectBackward0>)\n",
            "actions:  2\n",
            "Current_q_value tensor(0.1475, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2470, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.2278, grad_fn=<SelectBackward0>)\n",
            "actions:  53\n",
            "Current_q_value tensor(-0.1481, grad_fn=<SelectBackward0>)\n",
            "Episode 2, Total Reward: -12.297995859891671\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2492, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2253, grad_fn=<SelectBackward0>)\n",
            "actions:  101\n",
            "Current_q_value tensor(-0.0904, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2314, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2485, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2300, grad_fn=<SelectBackward0>)\n",
            "actions:  34\n",
            "Current_q_value tensor(0.0419, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(0.1306, grad_fn=<SelectBackward0>)\n",
            "actions:  113\n",
            "Current_q_value tensor(-0.0823, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(-0.0109, grad_fn=<SelectBackward0>)\n",
            "actions:  28\n",
            "Current_q_value tensor(-0.0163, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2482, grad_fn=<SelectBackward0>)\n",
            "actions:  20\n",
            "Current_q_value tensor(-0.0432, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2501, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(-0.0711, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2427, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2423, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2419, grad_fn=<SelectBackward0>)\n",
            "actions:  97\n",
            "Current_q_value tensor(0.0279, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2638, grad_fn=<SelectBackward0>)\n",
            "actions:  113\n",
            "Current_q_value tensor(-0.0546, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2397, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(-0.0425, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2382, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2377, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2371, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2364, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2358, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2351, grad_fn=<SelectBackward0>)\n",
            "actions:  11\n",
            "Current_q_value tensor(0.1490, grad_fn=<SelectBackward0>)\n",
            "actions:  61\n",
            "Current_q_value tensor(0.0332, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2694, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2948, grad_fn=<SelectBackward0>)\n",
            "actions:  3\n",
            "Current_q_value tensor(0.0786, grad_fn=<SelectBackward0>)\n",
            "actions:  37\n",
            "Current_q_value tensor(0.0928, grad_fn=<SelectBackward0>)\n",
            "Episode 3, Total Reward: 889.9751965103969\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2603, grad_fn=<SelectBackward0>)\n",
            "actions:  47\n",
            "Current_q_value tensor(0.0397, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.1504, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2506, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2134, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2821, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2420, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2834, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2381, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(0.1063, grad_fn=<SelectBackward0>)\n",
            "actions:  17\n",
            "Current_q_value tensor(0.0762, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2929, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2447, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2356, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2373, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(-0.0602, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2401, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.0874, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2544, grad_fn=<SelectBackward0>)\n",
            "actions:  125\n",
            "Current_q_value tensor(0.1148, grad_fn=<SelectBackward0>)\n",
            "actions:  28\n",
            "Current_q_value tensor(0.0387, grad_fn=<SelectBackward0>)\n",
            "actions:  94\n",
            "Current_q_value tensor(0.0546, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2959, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2419, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(0.1871, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2128, grad_fn=<SelectBackward0>)\n",
            "actions:  62\n",
            "Current_q_value tensor(-0.1336, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3006, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2331, grad_fn=<SelectBackward0>)\n",
            "actions:  19\n",
            "Current_q_value tensor(-0.0567, grad_fn=<SelectBackward0>)\n",
            "Episode 4, Total Reward: 39.834218918047554\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2635, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(-0.0119, grad_fn=<SelectBackward0>)\n",
            "actions:  83\n",
            "Current_q_value tensor(-0.0846, grad_fn=<SelectBackward0>)\n",
            "actions:  6\n",
            "Current_q_value tensor(0.1591, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(0.1252, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2500, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2501, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2501, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2501, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2501, grad_fn=<SelectBackward0>)\n",
            "actions:  95\n",
            "Current_q_value tensor(-0.0712, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2481, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2859, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.2461, grad_fn=<SelectBackward0>)\n",
            "actions:  59\n",
            "Current_q_value tensor(0.1153, grad_fn=<SelectBackward0>)\n",
            "Episode 5, Total Reward: 184.79973734966916\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2620, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2365, grad_fn=<SelectBackward0>)\n",
            "actions:  33\n",
            "Current_q_value tensor(0.1318, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(0.0358, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2420, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2417, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2414, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2411, grad_fn=<SelectBackward0>)\n",
            "actions:  25\n",
            "Current_q_value tensor(0.1420, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2306, grad_fn=<SelectBackward0>)\n",
            "actions:  62\n",
            "Current_q_value tensor(-0.0524, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2297, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2292, grad_fn=<SelectBackward0>)\n",
            "actions:  97\n",
            "Current_q_value tensor(0.0523, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2488, grad_fn=<SelectBackward0>)\n",
            "actions:  5\n",
            "Current_q_value tensor(-0.1253, grad_fn=<SelectBackward0>)\n",
            "Episode 6, Total Reward: 354.6393815051597\n",
            "actions:  76\n",
            "Current_q_value tensor(-0.1031, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2666, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(-0.0056, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(0.0162, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(0.1550, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2365, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2365, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2365, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2364, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2363, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2363, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2362, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2361, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2360, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2359, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2358, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2357, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2355, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.1650, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2494, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(0.1721, grad_fn=<SelectBackward0>)\n",
            "actions:  73\n",
            "Current_q_value tensor(-0.1240, grad_fn=<SelectBackward0>)\n",
            "Episode 7, Total Reward: 143.49920722848583\n",
            "actions:  28\n",
            "Current_q_value tensor(0.0120, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2758, grad_fn=<SelectBackward0>)\n",
            "actions:  124\n",
            "Current_q_value tensor(0.1413, grad_fn=<SelectBackward0>)\n",
            "actions:  123\n",
            "Current_q_value tensor(0.0774, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(-0.1268, grad_fn=<SelectBackward0>)\n",
            "actions:  59\n",
            "Current_q_value tensor(0.1298, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(0.1686, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2267, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2270, grad_fn=<SelectBackward0>)\n",
            "actions:  123\n",
            "Current_q_value tensor(0.0811, grad_fn=<SelectBackward0>)\n",
            "actions:  101\n",
            "Current_q_value tensor(-0.0493, grad_fn=<SelectBackward0>)\n",
            "actions:  42\n",
            "Current_q_value tensor(-0.1766, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2396, grad_fn=<SelectBackward0>)\n",
            "actions:  70\n",
            "Current_q_value tensor(-0.0166, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2393, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2392, grad_fn=<SelectBackward0>)\n",
            "actions:  47\n",
            "Current_q_value tensor(0.0759, grad_fn=<SelectBackward0>)\n",
            "actions:  117\n",
            "Current_q_value tensor(-0.2088, grad_fn=<SelectBackward0>)\n",
            "Episode 8, Total Reward: 1268.7022987140554\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2887, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2385, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2385, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2385, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2385, grad_fn=<SelectBackward0>)\n",
            "actions:  43\n",
            "Current_q_value tensor(0.1612, grad_fn=<SelectBackward0>)\n",
            "actions:  49\n",
            "Current_q_value tensor(0.0151, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(0.2668, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(0.2672, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(-0.1391, grad_fn=<SelectBackward0>)\n",
            "Episode 9, Total Reward: 108.83836658239125\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2911, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2393, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2394, grad_fn=<SelectBackward0>)\n",
            "actions:  115\n",
            "Current_q_value tensor(0.0448, grad_fn=<SelectBackward0>)\n",
            "actions:  4\n",
            "Current_q_value tensor(0.1492, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2464, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2464, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(0.2021, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2463, grad_fn=<SelectBackward0>)\n",
            "actions:  47\n",
            "Current_q_value tensor(0.1050, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2540, grad_fn=<SelectBackward0>)\n",
            "actions:  86\n",
            "Current_q_value tensor(-0.1050, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2532, grad_fn=<SelectBackward0>)\n",
            "actions:  21\n",
            "Current_q_value tensor(-0.0243, grad_fn=<SelectBackward0>)\n",
            "Episode 10, Total Reward: 247.25866196822244\n",
            "actions:  21\n",
            "Current_q_value tensor(-0.0038, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2781, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2392, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2827, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2391, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2878, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2381, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2929, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2362, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.1912, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3285, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2471, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3369, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2458, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(0.0926, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3493, grad_fn=<SelectBackward0>)\n",
            "actions:  61\n",
            "Current_q_value tensor(0.0689, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2690, grad_fn=<SelectBackward0>)\n",
            "actions:  101\n",
            "Current_q_value tensor(0.0278, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3828, grad_fn=<SelectBackward0>)\n",
            "actions:  73\n",
            "Current_q_value tensor(-0.0668, grad_fn=<SelectBackward0>)\n",
            "Episode 11, Total Reward: 1044.106174260245\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3131, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(-0.0331, grad_fn=<SelectBackward0>)\n",
            "actions:  112\n",
            "Current_q_value tensor(0.0358, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(0.2508, grad_fn=<SelectBackward0>)\n",
            "actions:  75\n",
            "Current_q_value tensor(-0.0003, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2547, grad_fn=<SelectBackward0>)\n",
            "actions:  78\n",
            "Current_q_value tensor(0.0150, grad_fn=<SelectBackward0>)\n",
            "actions:  15\n",
            "Current_q_value tensor(0.1203, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2509, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(0.0014, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.2512, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.1766, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2744, grad_fn=<SelectBackward0>)\n",
            "actions:  1\n",
            "Current_q_value tensor(0.0249, grad_fn=<SelectBackward0>)\n",
            "Episode 12, Total Reward: 986.7218281496116\n",
            "actions:  4\n",
            "Current_q_value tensor(0.1954, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3302, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(0.2365, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(0.2369, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(0.2369, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(0.1479, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.2374, grad_fn=<SelectBackward0>)\n",
            "actions:  65\n",
            "Current_q_value tensor(0.0427, grad_fn=<SelectBackward0>)\n",
            "actions:  30\n",
            "Current_q_value tensor(-0.0611, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.2982, grad_fn=<SelectBackward0>)\n",
            "actions:  51\n",
            "Current_q_value tensor(-0.0406, grad_fn=<SelectBackward0>)\n",
            "actions:  44\n",
            "Current_q_value tensor(-0.0549, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.2647, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2364, grad_fn=<SelectBackward0>)\n",
            "actions:  110\n",
            "Current_q_value tensor(0.0051, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3638, grad_fn=<SelectBackward0>)\n",
            "actions:  98\n",
            "Current_q_value tensor(-0.1225, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.2762, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3121, grad_fn=<SelectBackward0>)\n",
            "actions:  49\n",
            "Current_q_value tensor(-0.1213, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.4431, grad_fn=<SelectBackward0>)\n",
            "actions:  27\n",
            "Current_q_value tensor(0.0266, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(-0.0853, grad_fn=<SelectBackward0>)\n",
            "Episode 13, Total Reward: 288.0591727667779\n",
            "actions:  71\n",
            "Current_q_value tensor(-0.0774, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.4206, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2945, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2960, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2972, grad_fn=<SelectBackward0>)\n",
            "actions:  40\n",
            "Current_q_value tensor(0.0281, grad_fn=<SelectBackward0>)\n",
            "actions:  27\n",
            "Current_q_value tensor(0.0337, grad_fn=<SelectBackward0>)\n",
            "actions:  21\n",
            "Current_q_value tensor(0.0303, grad_fn=<SelectBackward0>)\n",
            "actions:  62\n",
            "Current_q_value tensor(-0.1210, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3719, grad_fn=<SelectBackward0>)\n",
            "actions:  94\n",
            "Current_q_value tensor(0.0532, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5408, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3553, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5504, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3501, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5650, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3453, grad_fn=<SelectBackward0>)\n",
            "actions:  68\n",
            "Current_q_value tensor(0.0829, grad_fn=<SelectBackward0>)\n",
            "actions:  104\n",
            "Current_q_value tensor(0.1389, grad_fn=<SelectBackward0>)\n",
            "actions:  5\n",
            "Current_q_value tensor(-0.1150, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5679, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3302, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5912, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.3318, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6143, grad_fn=<SelectBackward0>)\n",
            "actions:  21\n",
            "Current_q_value tensor(-0.0110, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3406, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3821, grad_fn=<SelectBackward0>)\n",
            "actions:  65\n",
            "Current_q_value tensor(-0.0176, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(0.2340, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(-0.0827, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(-0.0948, grad_fn=<SelectBackward0>)\n",
            "actions:  17\n",
            "Current_q_value tensor(0.0514, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.4116, grad_fn=<SelectBackward0>)\n",
            "actions:  59\n",
            "Current_q_value tensor(0.2560, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(0.0304, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7479, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.4300, grad_fn=<SelectBackward0>)\n",
            "actions:  26\n",
            "Current_q_value tensor(-0.0783, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6667, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3759, grad_fn=<SelectBackward0>)\n",
            "actions:  87\n",
            "Current_q_value tensor(-0.0234, grad_fn=<SelectBackward0>)\n",
            "Episode 14, Total Reward: 1292.411711846058\n",
            "actions:  119\n",
            "Current_q_value tensor(0.4150, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.2817, grad_fn=<SelectBackward0>)\n",
            "actions:  18\n",
            "Current_q_value tensor(-0.1695, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.2841, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.2986, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.2818, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.2725, grad_fn=<SelectBackward0>)\n",
            "actions:  85\n",
            "Current_q_value tensor(-0.0141, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3171, grad_fn=<SelectBackward0>)\n",
            "actions:  90\n",
            "Current_q_value tensor(0.1625, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3103, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3377, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(0.1883, grad_fn=<SelectBackward0>)\n",
            "actions:  18\n",
            "Current_q_value tensor(-0.1568, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3382, grad_fn=<SelectBackward0>)\n",
            "actions:  106\n",
            "Current_q_value tensor(-0.0411, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3616, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(0.2102, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(0.2138, grad_fn=<SelectBackward0>)\n",
            "actions:  96\n",
            "Current_q_value tensor(-0.1413, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3214, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3821, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3116, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3851, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.3089, grad_fn=<SelectBackward0>)\n",
            "actions:  18\n",
            "Current_q_value tensor(-0.1077, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3528, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.4383, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(-0.0209, grad_fn=<SelectBackward0>)\n",
            "Episode 15, Total Reward: 1094.7664411278784\n",
            "actions:  27\n",
            "Current_q_value tensor(0.1034, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5220, grad_fn=<SelectBackward0>)\n",
            "actions:  123\n",
            "Current_q_value tensor(0.1267, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.4313, grad_fn=<SelectBackward0>)\n",
            "actions:  24\n",
            "Current_q_value tensor(-0.0704, grad_fn=<SelectBackward0>)\n",
            "actions:  123\n",
            "Current_q_value tensor(0.1335, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3063, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.4695, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.3095, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3393, grad_fn=<SelectBackward0>)\n",
            "actions:  25\n",
            "Current_q_value tensor(0.1771, grad_fn=<SelectBackward0>)\n",
            "actions:  58\n",
            "Current_q_value tensor(-0.1022, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5590, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(0.1416, grad_fn=<SelectBackward0>)\n",
            "actions:  76\n",
            "Current_q_value tensor(-0.1372, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4235, grad_fn=<SelectBackward0>)\n",
            "actions:  34\n",
            "Current_q_value tensor(0.0322, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4042, grad_fn=<SelectBackward0>)\n",
            "actions:  103\n",
            "Current_q_value tensor(0.0982, grad_fn=<SelectBackward0>)\n",
            "actions:  59\n",
            "Current_q_value tensor(0.3529, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5579, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.7895, grad_fn=<SelectBackward0>)\n",
            "actions:  69\n",
            "Current_q_value tensor(-0.0670, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5322, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.7698, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5207, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.7748, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5105, grad_fn=<SelectBackward0>)\n",
            "actions:  9\n",
            "Current_q_value tensor(0.0376, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.7995, grad_fn=<SelectBackward0>)\n",
            "actions:  1\n",
            "Current_q_value tensor(0.1466, grad_fn=<SelectBackward0>)\n",
            "Episode 16, Total Reward: 2386.494767847571\n",
            "actions:  119\n",
            "Current_q_value tensor(0.4640, grad_fn=<SelectBackward0>)\n",
            "actions:  43\n",
            "Current_q_value tensor(0.3036, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2346, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4249, grad_fn=<SelectBackward0>)\n",
            "actions:  62\n",
            "Current_q_value tensor(-0.0877, grad_fn=<SelectBackward0>)\n",
            "actions:  37\n",
            "Current_q_value tensor(0.0787, grad_fn=<SelectBackward0>)\n",
            "Episode 17, Total Reward: 174.49889002667987\n",
            "actions:  119\n",
            "Current_q_value tensor(0.4666, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.4893, grad_fn=<SelectBackward0>)\n",
            "actions:  53\n",
            "Current_q_value tensor(-0.1308, grad_fn=<SelectBackward0>)\n",
            "actions:  58\n",
            "Current_q_value tensor(-0.0046, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(0.1901, grad_fn=<SelectBackward0>)\n",
            "actions:  49\n",
            "Current_q_value tensor(-0.0731, grad_fn=<SelectBackward0>)\n",
            "actions:  2\n",
            "Current_q_value tensor(0.1300, grad_fn=<SelectBackward0>)\n",
            "actions:  1\n",
            "Current_q_value tensor(0.1317, grad_fn=<SelectBackward0>)\n",
            "Episode 18, Total Reward: 920.0759706167737\n",
            "actions:  74\n",
            "Current_q_value tensor(-0.1894, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.4677, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5566, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.3664, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4105, grad_fn=<SelectBackward0>)\n",
            "actions:  57\n",
            "Current_q_value tensor(0.2360, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(0.0741, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4604, grad_fn=<SelectBackward0>)\n",
            "actions:  34\n",
            "Current_q_value tensor(0.1411, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5030, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4740, grad_fn=<SelectBackward0>)\n",
            "actions:  73\n",
            "Current_q_value tensor(-0.0408, grad_fn=<SelectBackward0>)\n",
            "Episode 19, Total Reward: 1070.434915170279\n",
            "actions:  119\n",
            "Current_q_value tensor(0.4869, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.6560, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.3894, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.3273, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4339, grad_fn=<SelectBackward0>)\n",
            "actions:  14\n",
            "Current_q_value tensor(0.1298, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4019, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4384, grad_fn=<SelectBackward0>)\n",
            "actions:  14\n",
            "Current_q_value tensor(0.1470, grad_fn=<SelectBackward0>)\n",
            "actions:  112\n",
            "Current_q_value tensor(0.0027, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4076, grad_fn=<SelectBackward0>)\n",
            "actions:  31\n",
            "Current_q_value tensor(-0.2973, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5114, grad_fn=<SelectBackward0>)\n",
            "actions:  112\n",
            "Current_q_value tensor(-0.0185, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.8272, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4821, grad_fn=<SelectBackward0>)\n",
            "actions:  73\n",
            "Current_q_value tensor(-0.0354, grad_fn=<SelectBackward0>)\n",
            "Episode 20, Total Reward: 1169.7174651101923\n",
            "actions:  17\n",
            "Current_q_value tensor(-0.0266, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5883, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.8250, grad_fn=<SelectBackward0>)\n",
            "actions:  36\n",
            "Current_q_value tensor(-0.2474, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5155, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.8807, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5132, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.9102, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5016, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.9424, grad_fn=<SelectBackward0>)\n",
            "actions:  41\n",
            "Current_q_value tensor(-0.1993, grad_fn=<SelectBackward0>)\n",
            "actions:  25\n",
            "Current_q_value tensor(0.3105, grad_fn=<SelectBackward0>)\n",
            "actions:  121\n",
            "Current_q_value tensor(0.2351, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.7659, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.2840, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.7243, grad_fn=<SelectBackward0>)\n",
            "actions:  127\n",
            "Current_q_value tensor(0.0205, grad_fn=<SelectBackward0>)\n",
            "Episode 21, Total Reward: 1467.8644218202353\n",
            "actions:  107\n",
            "Current_q_value tensor(0.6139, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5566, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4572, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4912, grad_fn=<SelectBackward0>)\n",
            "actions:  37\n",
            "Current_q_value tensor(0.1225, grad_fn=<SelectBackward0>)\n",
            "Episode 22, Total Reward: 81.8364848624733\n",
            "actions:  20\n",
            "Current_q_value tensor(-0.0731, grad_fn=<SelectBackward0>)\n",
            "actions:  4\n",
            "Current_q_value tensor(0.1586, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6185, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.9601, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(0.2729, grad_fn=<SelectBackward0>)\n",
            "actions:  57\n",
            "Current_q_value tensor(0.3255, grad_fn=<SelectBackward0>)\n",
            "actions:  57\n",
            "Current_q_value tensor(0.3398, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.4733, grad_fn=<SelectBackward0>)\n",
            "actions:  103\n",
            "Current_q_value tensor(0.2525, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-0.0019, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6041, grad_fn=<SelectBackward0>)\n",
            "actions:  84\n",
            "Current_q_value tensor(-0.1546, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(0.3923, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.8683, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6161, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5733, grad_fn=<SelectBackward0>)\n",
            "actions:  85\n",
            "Current_q_value tensor(0.1605, grad_fn=<SelectBackward0>)\n",
            "actions:  121\n",
            "Current_q_value tensor(0.4691, grad_fn=<SelectBackward0>)\n",
            "actions:  81\n",
            "Current_q_value tensor(0.1328, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7562, grad_fn=<SelectBackward0>)\n",
            "actions:  20\n",
            "Current_q_value tensor(0.1416, grad_fn=<SelectBackward0>)\n",
            "actions:  47\n",
            "Current_q_value tensor(0.3862, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(0.3171, grad_fn=<SelectBackward0>)\n",
            "actions:  70\n",
            "Current_q_value tensor(0.1485, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.1118, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.8589, grad_fn=<SelectBackward0>)\n",
            "actions:  44\n",
            "Current_q_value tensor(0.1128, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.8111, grad_fn=<SelectBackward0>)\n",
            "actions:  41\n",
            "Current_q_value tensor(-0.3881, grad_fn=<SelectBackward0>)\n",
            "actions:  89\n",
            "Current_q_value tensor(0.1067, grad_fn=<SelectBackward0>)\n",
            "actions:  21\n",
            "Current_q_value tensor(0.1801, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(0.0956, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(0.5360, grad_fn=<SelectBackward0>)\n",
            "actions:  49\n",
            "Current_q_value tensor(-0.1761, grad_fn=<SelectBackward0>)\n",
            "Episode 23, Total Reward: 3139.4143840836514\n",
            "actions:  107\n",
            "Current_q_value tensor(0.7003, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6441, grad_fn=<SelectBackward0>)\n",
            "actions:  94\n",
            "Current_q_value tensor(0.2170, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5538, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6033, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5589, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6070, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5625, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6086, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5651, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3231, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.1429, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(0.3556, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6374, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(0.3699, grad_fn=<SelectBackward0>)\n",
            "actions:  43\n",
            "Current_q_value tensor(0.3364, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.0331, grad_fn=<SelectBackward0>)\n",
            "actions:  0\n",
            "Current_q_value tensor(0.1565, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6866, grad_fn=<SelectBackward0>)\n",
            "actions:  65\n",
            "Current_q_value tensor(-0.2861, grad_fn=<SelectBackward0>)\n",
            "actions:  113\n",
            "Current_q_value tensor(0.0777, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.7941, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.4950, grad_fn=<SelectBackward0>)\n",
            "actions:  70\n",
            "Current_q_value tensor(0.1165, grad_fn=<SelectBackward0>)\n",
            "actions:  53\n",
            "Current_q_value tensor(-0.2021, grad_fn=<SelectBackward0>)\n",
            "actions:  11\n",
            "Current_q_value tensor(0.2560, grad_fn=<SelectBackward0>)\n",
            "actions:  123\n",
            "Current_q_value tensor(0.2901, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.9276, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.1799, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.9074, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(0.4494, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(0.1204, grad_fn=<SelectBackward0>)\n",
            "Episode 24, Total Reward: 37.12171287022284\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5486, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.8781, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.2671, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(0.3868, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6354, grad_fn=<SelectBackward0>)\n",
            "actions:  102\n",
            "Current_q_value tensor(0.0935, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(0.0816, grad_fn=<SelectBackward0>)\n",
            "actions:  50\n",
            "Current_q_value tensor(-0.1038, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5870, grad_fn=<SelectBackward0>)\n",
            "actions:  2\n",
            "Current_q_value tensor(0.1966, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6351, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(0.2776, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5863, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6330, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5857, grad_fn=<SelectBackward0>)\n",
            "actions:  86\n",
            "Current_q_value tensor(0.0216, grad_fn=<SelectBackward0>)\n",
            "actions:  4\n",
            "Current_q_value tensor(0.3360, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(-0.1434, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6338, grad_fn=<SelectBackward0>)\n",
            "actions:  116\n",
            "Current_q_value tensor(-0.1142, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5853, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6287, grad_fn=<SelectBackward0>)\n",
            "actions:  104\n",
            "Current_q_value tensor(0.1672, grad_fn=<SelectBackward0>)\n",
            "actions:  19\n",
            "Current_q_value tensor(-0.0632, grad_fn=<SelectBackward0>)\n",
            "Episode 25, Total Reward: 948.3045953142719\n",
            "actions:  107\n",
            "Current_q_value tensor(0.8784, grad_fn=<SelectBackward0>)\n",
            "actions:  14\n",
            "Current_q_value tensor(0.2746, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7152, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(0.1346, grad_fn=<SelectBackward0>)\n",
            "actions:  88\n",
            "Current_q_value tensor(-0.0546, grad_fn=<SelectBackward0>)\n",
            "actions:  124\n",
            "Current_q_value tensor(0.1572, grad_fn=<SelectBackward0>)\n",
            "actions:  30\n",
            "Current_q_value tensor(0.1555, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5740, grad_fn=<SelectBackward0>)\n",
            "actions:  117\n",
            "Current_q_value tensor(-0.1939, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6262, grad_fn=<SelectBackward0>)\n",
            "actions:  112\n",
            "Current_q_value tensor(0.1456, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5782, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6161, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5776, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6121, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5773, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6077, grad_fn=<SelectBackward0>)\n",
            "actions:  11\n",
            "Current_q_value tensor(0.0700, grad_fn=<SelectBackward0>)\n",
            "actions:  68\n",
            "Current_q_value tensor(0.2131, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5694, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(0.5086, grad_fn=<SelectBackward0>)\n",
            "actions:  41\n",
            "Current_q_value tensor(-0.1173, grad_fn=<SelectBackward0>)\n",
            "actions:  78\n",
            "Current_q_value tensor(0.0381, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7764, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5781, grad_fn=<SelectBackward0>)\n",
            "actions:  55\n",
            "Current_q_value tensor(-2.0489e-05, grad_fn=<SelectBackward0>)\n",
            "Episode 26, Total Reward: -5.445416011134512\n",
            "actions:  55\n",
            "Current_q_value tensor(0.1030, grad_fn=<SelectBackward0>)\n",
            "Episode 27, Total Reward: 0.0\n",
            "actions:  112\n",
            "Current_q_value tensor(0.0169, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.8923, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7429, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5666, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(0.1705, grad_fn=<SelectBackward0>)\n",
            "Episode 28, Total Reward: 1071.6300400462987\n",
            "actions:  107\n",
            "Current_q_value tensor(0.9457, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7566, grad_fn=<SelectBackward0>)\n",
            "actions:  45\n",
            "Current_q_value tensor(0.0734, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.5769, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.2734, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7748, grad_fn=<SelectBackward0>)\n",
            "actions:  46\n",
            "Current_q_value tensor(0.0539, grad_fn=<SelectBackward0>)\n",
            "actions:  89\n",
            "Current_q_value tensor(0.2861, grad_fn=<SelectBackward0>)\n",
            "actions:  64\n",
            "Current_q_value tensor(-0.0411, grad_fn=<SelectBackward0>)\n",
            "actions:  63\n",
            "Current_q_value tensor(-0.0083, grad_fn=<SelectBackward0>)\n",
            "Episode 29, Total Reward: 182.1354042358471\n",
            "actions:  107\n",
            "Current_q_value tensor(1.0148, grad_fn=<SelectBackward0>)\n",
            "actions:  124\n",
            "Current_q_value tensor(0.2172, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.8072, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.5904, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6832, grad_fn=<SelectBackward0>)\n",
            "actions:  102\n",
            "Current_q_value tensor(0.1332, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.0121, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6852, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.0235, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6861, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.0368, grad_fn=<SelectBackward0>)\n",
            "actions:  102\n",
            "Current_q_value tensor(0.2888, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6874, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.0604, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.6845, grad_fn=<SelectBackward0>)\n",
            "actions:  22\n",
            "Current_q_value tensor(-0.3502, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.0794, grad_fn=<SelectBackward0>)\n",
            "actions:  103\n",
            "Current_q_value tensor(0.4076, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7968, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.2308, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7993, grad_fn=<SelectBackward0>)\n",
            "actions:  65\n",
            "Current_q_value tensor(-0.4284, grad_fn=<SelectBackward0>)\n",
            "actions:  22\n",
            "Current_q_value tensor(-0.3426, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-0.2577, grad_fn=<SelectBackward0>)\n",
            "actions:  11\n",
            "Current_q_value tensor(0.0420, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(0.2853, grad_fn=<SelectBackward0>)\n",
            "actions:  74\n",
            "Current_q_value tensor(-0.2678, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.4579, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.9660, grad_fn=<SelectBackward0>)\n",
            "actions:  98\n",
            "Current_q_value tensor(-0.2305, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.2348, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.8201, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.2457, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-0.2717, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7566, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.1977, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(0.5892, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.7558, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(0.6274, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.2154, grad_fn=<SelectBackward0>)\n",
            "actions:  124\n",
            "Current_q_value tensor(0.3917, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.6852, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(0.3237, grad_fn=<SelectBackward0>)\n",
            "actions:  31\n",
            "Current_q_value tensor(-0.1634, grad_fn=<SelectBackward0>)\n",
            "actions:  71\n",
            "Current_q_value tensor(-0.0352, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.1641, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.7295, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.1616, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.7349, grad_fn=<SelectBackward0>)\n",
            "actions:  64\n",
            "Current_q_value tensor(0.1607, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.0769, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.6254, grad_fn=<SelectBackward0>)\n",
            "actions:  97\n",
            "Current_q_value tensor(0.0788, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.0521, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.0176, grad_fn=<SelectBackward0>)\n",
            "actions:  19\n",
            "Current_q_value tensor(0.0472, grad_fn=<SelectBackward0>)\n",
            "Episode 30, Total Reward: 1108.8509716207736\n",
            "actions:  66\n",
            "Current_q_value tensor(0.2879, grad_fn=<SelectBackward0>)\n",
            "actions:  94\n",
            "Current_q_value tensor(0.3357, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.0575, grad_fn=<SelectBackward0>)\n",
            "actions:  50\n",
            "Current_q_value tensor(0.0120, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(0.3885, grad_fn=<SelectBackward0>)\n",
            "actions:  70\n",
            "Current_q_value tensor(0.3193, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.9604, grad_fn=<SelectBackward0>)\n",
            "actions:  57\n",
            "Current_q_value tensor(0.3232, grad_fn=<SelectBackward0>)\n",
            "actions:  4\n",
            "Current_q_value tensor(0.4288, grad_fn=<SelectBackward0>)\n",
            "actions:  94\n",
            "Current_q_value tensor(0.4679, grad_fn=<SelectBackward0>)\n",
            "actions:  47\n",
            "Current_q_value tensor(0.4182, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.8829, grad_fn=<SelectBackward0>)\n",
            "actions:  40\n",
            "Current_q_value tensor(0.1181, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.9520, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.9137, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(0.0033, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.9944, grad_fn=<SelectBackward0>)\n",
            "actions:  19\n",
            "Current_q_value tensor(0.1387, grad_fn=<SelectBackward0>)\n",
            "Episode 31, Total Reward: 1025.7450251405207\n",
            "actions:  109\n",
            "Current_q_value tensor(0.1431, grad_fn=<SelectBackward0>)\n",
            "Episode 32, Total Reward: 0.0\n",
            "actions:  120\n",
            "Current_q_value tensor(0.1158, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.2278, grad_fn=<SelectBackward0>)\n",
            "actions:  81\n",
            "Current_q_value tensor(0.0314, grad_fn=<SelectBackward0>)\n",
            "actions:  117\n",
            "Current_q_value tensor(-0.1527, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.9456, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.7184, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(0.7871, grad_fn=<SelectBackward0>)\n",
            "actions:  75\n",
            "Current_q_value tensor(0.0489, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.9204, grad_fn=<SelectBackward0>)\n",
            "actions:  62\n",
            "Current_q_value tensor(-0.1021, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.0505, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.8518, grad_fn=<SelectBackward0>)\n",
            "actions:  17\n",
            "Current_q_value tensor(-0.0510, grad_fn=<SelectBackward0>)\n",
            "actions:  75\n",
            "Current_q_value tensor(0.0067, grad_fn=<SelectBackward0>)\n",
            "actions:  21\n",
            "Current_q_value tensor(0.3459, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.6639, grad_fn=<SelectBackward0>)\n",
            "actions:  47\n",
            "Current_q_value tensor(0.7213, grad_fn=<SelectBackward0>)\n",
            "Episode 33, Total Reward: 1061.287765831361\n",
            "actions:  107\n",
            "Current_q_value tensor(1.4100, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.0794, grad_fn=<SelectBackward0>)\n",
            "actions:  42\n",
            "Current_q_value tensor(-0.1789, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.7659, grad_fn=<SelectBackward0>)\n",
            "actions:  46\n",
            "Current_q_value tensor(0.2364, grad_fn=<SelectBackward0>)\n",
            "actions:  41\n",
            "Current_q_value tensor(-0.1973, grad_fn=<SelectBackward0>)\n",
            "actions:  65\n",
            "Current_q_value tensor(-0.5198, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.1809, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.7828, grad_fn=<SelectBackward0>)\n",
            "actions:  15\n",
            "Current_q_value tensor(0.2908, grad_fn=<SelectBackward0>)\n",
            "actions:  36\n",
            "Current_q_value tensor(-0.2695, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.0635, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.6435, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.0437, grad_fn=<SelectBackward0>)\n",
            "actions:  73\n",
            "Current_q_value tensor(0.0594, grad_fn=<SelectBackward0>)\n",
            "Episode 34, Total Reward: 53.1878956926339\n",
            "actions:  75\n",
            "Current_q_value tensor(-0.0946, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.5253, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.2126, grad_fn=<SelectBackward0>)\n",
            "actions:  115\n",
            "Current_q_value tensor(0.1590, grad_fn=<SelectBackward0>)\n",
            "actions:  3\n",
            "Current_q_value tensor(0.0233, grad_fn=<SelectBackward0>)\n",
            "actions:  46\n",
            "Current_q_value tensor(0.3572, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(0.8490, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(0.9848, grad_fn=<SelectBackward0>)\n",
            "actions:  25\n",
            "Current_q_value tensor(0.5882, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.4969, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.5820, grad_fn=<SelectBackward0>)\n",
            "actions:  46\n",
            "Current_q_value tensor(0.6070, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.2002, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.7330, grad_fn=<SelectBackward0>)\n",
            "actions:  92\n",
            "Current_q_value tensor(-0.4217, grad_fn=<SelectBackward0>)\n",
            "actions:  42\n",
            "Current_q_value tensor(0.0725, grad_fn=<SelectBackward0>)\n",
            "actions:  97\n",
            "Current_q_value tensor(-0.1527, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.2686, grad_fn=<SelectBackward0>)\n",
            "actions:  96\n",
            "Current_q_value tensor(-0.0539, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.1599, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(0.3305, grad_fn=<SelectBackward0>)\n",
            "actions:  87\n",
            "Current_q_value tensor(0.1625, grad_fn=<SelectBackward0>)\n",
            "actions:  50\n",
            "Current_q_value tensor(0.2680, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.4849, grad_fn=<SelectBackward0>)\n",
            "actions:  11\n",
            "Current_q_value tensor(-0.0728, grad_fn=<SelectBackward0>)\n",
            "actions:  31\n",
            "Current_q_value tensor(0.2189, grad_fn=<SelectBackward0>)\n",
            "Episode 35, Total Reward: 2792.0210097718427\n",
            "actions:  107\n",
            "Current_q_value tensor(1.7284, grad_fn=<SelectBackward0>)\n",
            "actions:  83\n",
            "Current_q_value tensor(-0.0743, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.2324, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(0.3684, grad_fn=<SelectBackward0>)\n",
            "Episode 36, Total Reward: 184.1350337316544\n",
            "actions:  25\n",
            "Current_q_value tensor(0.7374, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.9889, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.4867, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.1897, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(1.0788, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.8904, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.0680, grad_fn=<SelectBackward0>)\n",
            "actions:  71\n",
            "Current_q_value tensor(-0.2911, grad_fn=<SelectBackward0>)\n",
            "actions:  40\n",
            "Current_q_value tensor(0.2958, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.4949, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.3610, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.3244, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.6214, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.3579, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.6318, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-0.5334, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4479, grad_fn=<SelectBackward0>)\n",
            "actions:  30\n",
            "Current_q_value tensor(0.5776, grad_fn=<SelectBackward0>)\n",
            "actions:  83\n",
            "Current_q_value tensor(0.2771, grad_fn=<SelectBackward0>)\n",
            "actions:  121\n",
            "Current_q_value tensor(1.3763, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.0550, grad_fn=<SelectBackward0>)\n",
            "actions:  87\n",
            "Current_q_value tensor(0.7777, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.1938, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.3340, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.1938, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(1.6039, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.4463, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(4.3891, grad_fn=<SelectBackward0>)\n",
            "actions:  115\n",
            "Current_q_value tensor(1.0282, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.5200, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.4167, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.6146, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.5839, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.4421, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.6592, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.5009, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(0.1438, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.7200, grad_fn=<SelectBackward0>)\n",
            "actions:  66\n",
            "Current_q_value tensor(1.2960, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(0.9473, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.6208, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.8439, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.6540, grad_fn=<SelectBackward0>)\n",
            "actions:  62\n",
            "Current_q_value tensor(-0.0216, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.8942, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.6875, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.9276, grad_fn=<SelectBackward0>)\n",
            "actions:  95\n",
            "Current_q_value tensor(1.0624, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.7378, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(0.5263, grad_fn=<SelectBackward0>)\n",
            "actions:  51\n",
            "Current_q_value tensor(1.1107, grad_fn=<SelectBackward0>)\n",
            "Episode 37, Total Reward: 3357.35945913081\n",
            "actions:  60\n",
            "Current_q_value tensor(0.4770, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.1802, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.4632, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.3452, grad_fn=<SelectBackward0>)\n",
            "actions:  84\n",
            "Current_q_value tensor(0.1365, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.9179, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.2471, grad_fn=<SelectBackward0>)\n",
            "actions:  41\n",
            "Current_q_value tensor(-0.2232, grad_fn=<SelectBackward0>)\n",
            "actions:  26\n",
            "Current_q_value tensor(0.1855, grad_fn=<SelectBackward0>)\n",
            "actions:  18\n",
            "Current_q_value tensor(0.0548, grad_fn=<SelectBackward0>)\n",
            "actions:  90\n",
            "Current_q_value tensor(0.4093, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.6316, grad_fn=<SelectBackward0>)\n",
            "actions:  81\n",
            "Current_q_value tensor(-0.1351, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.1753, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.6229, grad_fn=<SelectBackward0>)\n",
            "actions:  84\n",
            "Current_q_value tensor(0.3589, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.9032, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(0.8011, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.6337, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.8945, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.6352, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.8882, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.6338, grad_fn=<SelectBackward0>)\n",
            "actions:  83\n",
            "Current_q_value tensor(0.5814, grad_fn=<SelectBackward0>)\n",
            "actions:  102\n",
            "Current_q_value tensor(1.1746, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(1.5067, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.2061, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.9651, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.2159, grad_fn=<SelectBackward0>)\n",
            "actions:  70\n",
            "Current_q_value tensor(0.6748, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.9827, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.2314, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.9911, grad_fn=<SelectBackward0>)\n",
            "actions:  30\n",
            "Current_q_value tensor(1.1857, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-1.0838, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.4927, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.2490, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.5033, grad_fn=<SelectBackward0>)\n",
            "actions:  96\n",
            "Current_q_value tensor(0.2381, grad_fn=<SelectBackward0>)\n",
            "actions:  112\n",
            "Current_q_value tensor(0.4497, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.2692, grad_fn=<SelectBackward0>)\n",
            "actions:  110\n",
            "Current_q_value tensor(-0.2506, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-1.3064, grad_fn=<SelectBackward0>)\n",
            "actions:  26\n",
            "Current_q_value tensor(0.5202, grad_fn=<SelectBackward0>)\n",
            "actions:  94\n",
            "Current_q_value tensor(1.5283, grad_fn=<SelectBackward0>)\n",
            "actions:  19\n",
            "Current_q_value tensor(0.8693, grad_fn=<SelectBackward0>)\n",
            "Episode 38, Total Reward: 1099.4224953229623\n",
            "actions:  15\n",
            "Current_q_value tensor(0.1153, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.6809, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.4164, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(0.4021, grad_fn=<SelectBackward0>)\n",
            "actions:  9\n",
            "Current_q_value tensor(-0.2769, grad_fn=<SelectBackward0>)\n",
            "actions:  49\n",
            "Current_q_value tensor(-0.0202, grad_fn=<SelectBackward0>)\n",
            "Episode 39, Total Reward: 1007.2325682727842\n",
            "actions:  63\n",
            "Current_q_value tensor(0.0859, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.7204, grad_fn=<SelectBackward0>)\n",
            "actions:  38\n",
            "Current_q_value tensor(0.0508, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.6214, grad_fn=<SelectBackward0>)\n",
            "Episode 40, Total Reward: 928.1308328178129\n",
            "actions:  107\n",
            "Current_q_value tensor(2.7868, grad_fn=<SelectBackward0>)\n",
            "actions:  67\n",
            "Current_q_value tensor(-0.4410, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.7777, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(0.6490, grad_fn=<SelectBackward0>)\n",
            "actions:  29\n",
            "Current_q_value tensor(-0.0575, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.4721, grad_fn=<SelectBackward0>)\n",
            "Episode 41, Total Reward: 647.9229582156986\n",
            "actions:  31\n",
            "Current_q_value tensor(0.0681, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(3.1949, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(1.1540, grad_fn=<SelectBackward0>)\n",
            "actions:  15\n",
            "Current_q_value tensor(0.3918, grad_fn=<SelectBackward0>)\n",
            "actions:  123\n",
            "Current_q_value tensor(0.3707, grad_fn=<SelectBackward0>)\n",
            "actions:  81\n",
            "Current_q_value tensor(-0.4296, grad_fn=<SelectBackward0>)\n",
            "Episode 42, Total Reward: 946.6095659969869\n",
            "actions:  64\n",
            "Current_q_value tensor(0.3952, grad_fn=<SelectBackward0>)\n",
            "actions:  120\n",
            "Current_q_value tensor(0.5319, grad_fn=<SelectBackward0>)\n",
            "actions:  30\n",
            "Current_q_value tensor(0.7234, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(3.2352, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.7363, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.4241, grad_fn=<SelectBackward0>)\n",
            "actions:  88\n",
            "Current_q_value tensor(0.0175, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.7028, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.4496, grad_fn=<SelectBackward0>)\n",
            "actions:  37\n",
            "Current_q_value tensor(0.2399, grad_fn=<SelectBackward0>)\n",
            "Episode 43, Total Reward: 1071.6300400462987\n",
            "actions:  61\n",
            "Current_q_value tensor(0.2901, grad_fn=<SelectBackward0>)\n",
            "actions:  92\n",
            "Current_q_value tensor(-0.3690, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(3.6731, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(0.7577, grad_fn=<SelectBackward0>)\n",
            "actions:  67\n",
            "Current_q_value tensor(-0.2704, grad_fn=<SelectBackward0>)\n",
            "actions:  62\n",
            "Current_q_value tensor(0.1334, grad_fn=<SelectBackward0>)\n",
            "actions:  61\n",
            "Current_q_value tensor(0.3367, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.2279, grad_fn=<SelectBackward0>)\n",
            "actions:  59\n",
            "Current_q_value tensor(0.7274, grad_fn=<SelectBackward0>)\n",
            "actions:  123\n",
            "Current_q_value tensor(0.7034, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(1.7139, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(3.2693, grad_fn=<SelectBackward0>)\n",
            "actions:  51\n",
            "Current_q_value tensor(1.1558, grad_fn=<SelectBackward0>)\n",
            "actions:  27\n",
            "Current_q_value tensor(1.5826, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-0.6628, grad_fn=<SelectBackward0>)\n",
            "actions:  112\n",
            "Current_q_value tensor(0.7718, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(7.5397, grad_fn=<SelectBackward0>)\n",
            "actions:  53\n",
            "Current_q_value tensor(-0.8632, grad_fn=<SelectBackward0>)\n",
            "actions:  110\n",
            "Current_q_value tensor(0.3428, grad_fn=<SelectBackward0>)\n",
            "actions:  44\n",
            "Current_q_value tensor(0.8438, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(4.6699, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(7.9876, grad_fn=<SelectBackward0>)\n",
            "actions:  80\n",
            "Current_q_value tensor(0.1201, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(4.6198, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(8.0963, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(0.8985, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(3.9172, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(7.3850, grad_fn=<SelectBackward0>)\n",
            "actions:  93\n",
            "Current_q_value tensor(0.4985, grad_fn=<SelectBackward0>)\n",
            "Episode 44, Total Reward: 974.1612006723444\n",
            "actions:  79\n",
            "Current_q_value tensor(0.3010, grad_fn=<SelectBackward0>)\n",
            "actions:  109\n",
            "Current_q_value tensor(0.3500, grad_fn=<SelectBackward0>)\n",
            "Episode 45, Total Reward: 0.0\n",
            "actions:  73\n",
            "Current_q_value tensor(0.6111, grad_fn=<SelectBackward0>)\n",
            "Episode 46, Total Reward: 0.0\n",
            "actions:  103\n",
            "Current_q_value tensor(0.8125, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(0.0867, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(4.4326, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.2225, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.7811, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.1809, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(6.1265, grad_fn=<SelectBackward0>)\n",
            "actions:  88\n",
            "Current_q_value tensor(0.4245, grad_fn=<SelectBackward0>)\n",
            "actions:  42\n",
            "Current_q_value tensor(0.5163, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(0.4293, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.1566, grad_fn=<SelectBackward0>)\n",
            "actions:  114\n",
            "Current_q_value tensor(0.5207, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.8799, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.1764, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.8903, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.1851, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(0.7271, grad_fn=<SelectBackward0>)\n",
            "actions:  23\n",
            "Current_q_value tensor(-0.5275, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(1.8823, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(2.3814, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(6.8820, grad_fn=<SelectBackward0>)\n",
            "actions:  41\n",
            "Current_q_value tensor(-0.6225, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.3984, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.0901, grad_fn=<SelectBackward0>)\n",
            "actions:  125\n",
            "Current_q_value tensor(0.2971, grad_fn=<SelectBackward0>)\n",
            "actions:  1\n",
            "Current_q_value tensor(1.1053, grad_fn=<SelectBackward0>)\n",
            "Episode 47, Total Reward: 1094.2179406230425\n",
            "actions:  69\n",
            "Current_q_value tensor(-0.3074, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(4.4235, grad_fn=<SelectBackward0>)\n",
            "actions:  103\n",
            "Current_q_value tensor(0.8258, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(0.4758, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.6484, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(1.9835, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.1647, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.7101, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.1893, grad_fn=<SelectBackward0>)\n",
            "actions:  127\n",
            "Current_q_value tensor(0.4201, grad_fn=<SelectBackward0>)\n",
            "Episode 48, Total Reward: 1734.5781418907682\n",
            "actions:  47\n",
            "Current_q_value tensor(1.3919, grad_fn=<SelectBackward0>)\n",
            "actions:  101\n",
            "Current_q_value tensor(1.1892, grad_fn=<SelectBackward0>)\n",
            "actions:  76\n",
            "Current_q_value tensor(-0.4974, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(5.2785, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4110, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.0168, grad_fn=<SelectBackward0>)\n",
            "actions:  116\n",
            "Current_q_value tensor(0.3837, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4737, grad_fn=<SelectBackward0>)\n",
            "actions:  13\n",
            "Current_q_value tensor(-0.7976, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(1.0229, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8563, grad_fn=<SelectBackward0>)\n",
            "actions:  65\n",
            "Current_q_value tensor(-1.3941, grad_fn=<SelectBackward0>)\n",
            "actions:  103\n",
            "Current_q_value tensor(1.8594, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(3.9739, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(9.3403, grad_fn=<SelectBackward0>)\n",
            "actions:  50\n",
            "Current_q_value tensor(1.1290, grad_fn=<SelectBackward0>)\n",
            "actions:  5\n",
            "Current_q_value tensor(0.2337, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(4.1494, grad_fn=<SelectBackward0>)\n",
            "actions:  5\n",
            "Current_q_value tensor(0.1638, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(9.3374, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.4241, grad_fn=<SelectBackward0>)\n",
            "actions:  55\n",
            "Current_q_value tensor(0.5927, grad_fn=<SelectBackward0>)\n",
            "Episode 49, Total Reward: 1883.2215578379983\n",
            "actions:  1\n",
            "Current_q_value tensor(1.3883, grad_fn=<SelectBackward0>)\n",
            "Episode 50, Total Reward: 0.0\n",
            "actions:  61\n",
            "Current_q_value tensor(0.8549, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(6.5658, grad_fn=<SelectBackward0>)\n",
            "actions:  6\n",
            "Current_q_value tensor(-0.1526, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.1397, grad_fn=<SelectBackward0>)\n",
            "actions:  116\n",
            "Current_q_value tensor(0.7865, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.9511, grad_fn=<SelectBackward0>)\n",
            "actions:  23\n",
            "Current_q_value tensor(-0.2076, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.7001, grad_fn=<SelectBackward0>)\n",
            "Episode 51, Total Reward: 1067.8610935713186\n",
            "actions:  107\n",
            "Current_q_value tensor(6.2209, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4067, grad_fn=<SelectBackward0>)\n",
            "actions:  26\n",
            "Current_q_value tensor(0.5901, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5534, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(7.3832, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(1.9844, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.5033, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.0264, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.5345, grad_fn=<SelectBackward0>)\n",
            "actions:  101\n",
            "Current_q_value tensor(0.4596, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(1.1552, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.3894, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8130, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4067, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8314, grad_fn=<SelectBackward0>)\n",
            "actions:  42\n",
            "Current_q_value tensor(0.6180, grad_fn=<SelectBackward0>)\n",
            "actions:  33\n",
            "Current_q_value tensor(0.1429, grad_fn=<SelectBackward0>)\n",
            "actions:  79\n",
            "Current_q_value tensor(0.5355, grad_fn=<SelectBackward0>)\n",
            "actions:  55\n",
            "Current_q_value tensor(0.6804, grad_fn=<SelectBackward0>)\n",
            "Episode 52, Total Reward: 1354.6679583123296\n",
            "actions:  28\n",
            "Current_q_value tensor(0.2942, grad_fn=<SelectBackward0>)\n",
            "actions:  23\n",
            "Current_q_value tensor(0.7677, grad_fn=<SelectBackward0>)\n",
            "actions:  102\n",
            "Current_q_value tensor(1.8265, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(6.9323, grad_fn=<SelectBackward0>)\n",
            "actions:  66\n",
            "Current_q_value tensor(1.0496, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.7277, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(0.3152, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.3250, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8502, grad_fn=<SelectBackward0>)\n",
            "actions:  41\n",
            "Current_q_value tensor(-0.5550, grad_fn=<SelectBackward0>)\n",
            "actions:  67\n",
            "Current_q_value tensor(0.0394, grad_fn=<SelectBackward0>)\n",
            "actions:  84\n",
            "Current_q_value tensor(1.0380, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.1174, grad_fn=<SelectBackward0>)\n",
            "actions:  92\n",
            "Current_q_value tensor(-0.0011, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.7464, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.1098, grad_fn=<SelectBackward0>)\n",
            "actions:  23\n",
            "Current_q_value tensor(0.6141, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(0.5685, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(0.9153, grad_fn=<SelectBackward0>)\n",
            "actions:  118\n",
            "Current_q_value tensor(0.9926, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(3.2678, grad_fn=<SelectBackward0>)\n",
            "actions:  95\n",
            "Current_q_value tensor(1.6227, grad_fn=<SelectBackward0>)\n",
            "actions:  52\n",
            "Current_q_value tensor(-0.4496, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(6.7122, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.5221, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.0238, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.5610, grad_fn=<SelectBackward0>)\n",
            "actions:  42\n",
            "Current_q_value tensor(1.0327, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.0297, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.6190, grad_fn=<SelectBackward0>)\n",
            "actions:  76\n",
            "Current_q_value tensor(0.2911, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.0317, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.6698, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.0235, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(1.5631, grad_fn=<SelectBackward0>)\n",
            "actions:  29\n",
            "Current_q_value tensor(0.2420, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.4270, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8709, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.4795, grad_fn=<SelectBackward0>)\n",
            "actions:  68\n",
            "Current_q_value tensor(1.0824, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8767, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.5569, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8662, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.5884, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8493, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.6178, grad_fn=<SelectBackward0>)\n",
            "actions:  92\n",
            "Current_q_value tensor(0.3861, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8367, grad_fn=<SelectBackward0>)\n",
            "actions:  118\n",
            "Current_q_value tensor(1.1710, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.6681, grad_fn=<SelectBackward0>)\n",
            "actions:  83\n",
            "Current_q_value tensor(0.9014, grad_fn=<SelectBackward0>)\n",
            "Episode 53, Total Reward: 1606.6856522134221\n",
            "actions:  107\n",
            "Current_q_value tensor(7.6017, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(0.9406, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.9508, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.2280, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(1.2727, grad_fn=<SelectBackward0>)\n",
            "actions:  59\n",
            "Current_q_value tensor(0.8226, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.1758, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(0.9095, grad_fn=<SelectBackward0>)\n",
            "actions:  6\n",
            "Current_q_value tensor(0.4083, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4096, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(1.9097, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.2651, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4077, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.2929, grad_fn=<SelectBackward0>)\n",
            "actions:  40\n",
            "Current_q_value tensor(0.5232, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4135, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.3405, grad_fn=<SelectBackward0>)\n",
            "actions:  45\n",
            "Current_q_value tensor(0.8190, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.3320, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.2897, grad_fn=<SelectBackward0>)\n",
            "actions:  61\n",
            "Current_q_value tensor(0.7508, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(3.2181, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(1.1993, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(11.1990, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(3.0426, grad_fn=<SelectBackward0>)\n",
            "actions:  9\n",
            "Current_q_value tensor(-1.2360, grad_fn=<SelectBackward0>)\n",
            "actions:  73\n",
            "Current_q_value tensor(2.4747, grad_fn=<SelectBackward0>)\n",
            "Episode 54, Total Reward: 1155.6748948626537\n",
            "actions:  107\n",
            "Current_q_value tensor(7.6664, grad_fn=<SelectBackward0>)\n",
            "actions:  24\n",
            "Current_q_value tensor(0.0955, grad_fn=<SelectBackward0>)\n",
            "actions:  2\n",
            "Current_q_value tensor(0.8044, grad_fn=<SelectBackward0>)\n",
            "actions:  83\n",
            "Current_q_value tensor(0.4811, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.3401, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.6756, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.1923, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.2031, grad_fn=<SelectBackward0>)\n",
            "actions:  78\n",
            "Current_q_value tensor(0.3376, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.2201, grad_fn=<SelectBackward0>)\n",
            "actions:  8\n",
            "Current_q_value tensor(0.2938, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.2651, grad_fn=<SelectBackward0>)\n",
            "actions:  85\n",
            "Current_q_value tensor(0.9828, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(3.1191, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(3.2920, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.8999, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(3.3063, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(2.9078, grad_fn=<SelectBackward0>)\n",
            "actions:  15\n",
            "Current_q_value tensor(0.3955, grad_fn=<SelectBackward0>)\n",
            "actions:  89\n",
            "Current_q_value tensor(0.3784, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(1.9223, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(1.5406, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(3.5087, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(3.1444, grad_fn=<SelectBackward0>)\n",
            "actions:  53\n",
            "Current_q_value tensor(-0.3047, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(2.4711, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(2.0971, grad_fn=<SelectBackward0>)\n",
            "actions:  92\n",
            "Current_q_value tensor(0.9044, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.7011, grad_fn=<SelectBackward0>)\n",
            "actions:  68\n",
            "Current_q_value tensor(2.0009, grad_fn=<SelectBackward0>)\n",
            "actions:  57\n",
            "Current_q_value tensor(1.1812, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.4179, grad_fn=<SelectBackward0>)\n",
            "actions:  80\n",
            "Current_q_value tensor(0.9806, grad_fn=<SelectBackward0>)\n",
            "actions:  109\n",
            "Current_q_value tensor(0.7554, grad_fn=<SelectBackward0>)\n",
            "Episode 55, Total Reward: 389.827820143244\n",
            "actions:  107\n",
            "Current_q_value tensor(7.6843, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.4645, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4831, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.4853, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4907, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.5055, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4918, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(0.4094, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.5292, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4818, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.5482, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4746, grad_fn=<SelectBackward0>)\n",
            "actions:  73\n",
            "Current_q_value tensor(0.8259, grad_fn=<SelectBackward0>)\n",
            "Episode 56, Total Reward: 0.0\n",
            "actions:  117\n",
            "Current_q_value tensor(0.8919, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(7.2825, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.3960, grad_fn=<SelectBackward0>)\n",
            "actions:  55\n",
            "Current_q_value tensor(0.8639, grad_fn=<SelectBackward0>)\n",
            "Episode 57, Total Reward: 1009.9673176802844\n",
            "actions:  52\n",
            "Current_q_value tensor(0.2872, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(7.9053, grad_fn=<SelectBackward0>)\n",
            "actions:  114\n",
            "Current_q_value tensor(0.8329, grad_fn=<SelectBackward0>)\n",
            "actions:  78\n",
            "Current_q_value tensor(0.5034, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.6618, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4411, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.6981, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(0.0260, grad_fn=<SelectBackward0>)\n",
            "actions:  89\n",
            "Current_q_value tensor(0.4466, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.8120, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.0255, grad_fn=<SelectBackward0>)\n",
            "actions:  55\n",
            "Current_q_value tensor(0.9966, grad_fn=<SelectBackward0>)\n",
            "Episode 58, Total Reward: 1017.3463827896612\n",
            "actions:  119\n",
            "Current_q_value tensor(1.9249, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(9.8745, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4644, grad_fn=<SelectBackward0>)\n",
            "actions:  110\n",
            "Current_q_value tensor(0.2172, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(0.4878, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.8528, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(2.4490, grad_fn=<SelectBackward0>)\n",
            "actions:  106\n",
            "Current_q_value tensor(-0.2052, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(9.1655, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.9049, grad_fn=<SelectBackward0>)\n",
            "actions:  127\n",
            "Current_q_value tensor(0.9949, grad_fn=<SelectBackward0>)\n",
            "Episode 59, Total Reward: 928.1308328178129\n",
            "actions:  107\n",
            "Current_q_value tensor(9.4814, grad_fn=<SelectBackward0>)\n",
            "actions:  87\n",
            "Current_q_value tensor(0.9235, grad_fn=<SelectBackward0>)\n",
            "actions:  90\n",
            "Current_q_value tensor(0.6485, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(2.5924, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.4188, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(1.2897, grad_fn=<SelectBackward0>)\n",
            "actions:  34\n",
            "Current_q_value tensor(0.7814, grad_fn=<SelectBackward0>)\n",
            "actions:  47\n",
            "Current_q_value tensor(1.9505, grad_fn=<SelectBackward0>)\n",
            "actions:  28\n",
            "Current_q_value tensor(1.1346, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(3.4590, grad_fn=<SelectBackward0>)\n",
            "actions:  23\n",
            "Current_q_value tensor(1.6743, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(14.1075, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(4.0393, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(14.2086, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(3.8758, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(1.7282, grad_fn=<SelectBackward0>)\n",
            "Episode 60, Total Reward: 1083.6556147676638\n",
            "actions:  82\n",
            "Current_q_value tensor(2.5620, grad_fn=<SelectBackward0>)\n",
            "actions:  45\n",
            "Current_q_value tensor(2.0968, grad_fn=<SelectBackward0>)\n",
            "actions:  31\n",
            "Current_q_value tensor(0.4124, grad_fn=<SelectBackward0>)\n",
            "actions:  110\n",
            "Current_q_value tensor(1.7859, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(11.9954, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.6386, grad_fn=<SelectBackward0>)\n",
            "actions:  2\n",
            "Current_q_value tensor(1.7045, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(3.7277, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(0.9147, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(3.8860, grad_fn=<SelectBackward0>)\n",
            "actions:  68\n",
            "Current_q_value tensor(2.6486, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(3.9762, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(4.0123, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(4.0417, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(4.0648, grad_fn=<SelectBackward0>)\n",
            "actions:  125\n",
            "Current_q_value tensor(1.1993, grad_fn=<SelectBackward0>)\n",
            "actions:  37\n",
            "Current_q_value tensor(1.0754, grad_fn=<SelectBackward0>)\n",
            "Episode 61, Total Reward: 1392.4738816188674\n",
            "actions:  52\n",
            "Current_q_value tensor(0.9784, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(11.5089, grad_fn=<SelectBackward0>)\n",
            "actions:  27\n",
            "Current_q_value tensor(0.2874, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.1530, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.8842, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.2062, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(0.5788, grad_fn=<SelectBackward0>)\n",
            "actions:  97\n",
            "Current_q_value tensor(-0.9082, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.0722, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.2604, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.0112, grad_fn=<SelectBackward0>)\n",
            "actions:  65\n",
            "Current_q_value tensor(-1.1970, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.5420, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.6784, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(4.9914, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(17.1096, grad_fn=<SelectBackward0>)\n",
            "actions:  10\n",
            "Current_q_value tensor(2.9724, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.6743, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(-0.0813, grad_fn=<SelectBackward0>)\n",
            "actions:  110\n",
            "Current_q_value tensor(1.2738, grad_fn=<SelectBackward0>)\n",
            "actions:  11\n",
            "Current_q_value tensor(-0.8494, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.6874, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.3323, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.8576, grad_fn=<SelectBackward0>)\n",
            "actions:  38\n",
            "Current_q_value tensor(0.3261, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.5348, grad_fn=<SelectBackward0>)\n",
            "actions:  8\n",
            "Current_q_value tensor(1.4337, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.1153, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.6319, grad_fn=<SelectBackward0>)\n",
            "actions:  27\n",
            "Current_q_value tensor(1.4069, grad_fn=<SelectBackward0>)\n",
            "actions:  57\n",
            "Current_q_value tensor(0.6421, grad_fn=<SelectBackward0>)\n",
            "actions:  47\n",
            "Current_q_value tensor(3.5515, grad_fn=<SelectBackward0>)\n",
            "actions:  4\n",
            "Current_q_value tensor(2.2975, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.1372, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.7554, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.2461, grad_fn=<SelectBackward0>)\n",
            "actions:  26\n",
            "Current_q_value tensor(1.7446, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.8798, grad_fn=<SelectBackward0>)\n",
            "actions:  115\n",
            "Current_q_value tensor(1.9790, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.5601, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.0925, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.6550, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.1387, grad_fn=<SelectBackward0>)\n",
            "actions:  51\n",
            "Current_q_value tensor(2.9068, grad_fn=<SelectBackward0>)\n",
            "actions:  34\n",
            "Current_q_value tensor(2.5245, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.8462, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.3581, grad_fn=<SelectBackward0>)\n",
            "actions:  71\n",
            "Current_q_value tensor(0.4253, grad_fn=<SelectBackward0>)\n",
            "Episode 62, Total Reward: 1241.4691083391044\n",
            "actions:  103\n",
            "Current_q_value tensor(3.0871, grad_fn=<SelectBackward0>)\n",
            "actions:  22\n",
            "Current_q_value tensor(0.5449, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(14.0303, grad_fn=<SelectBackward0>)\n",
            "actions:  16\n",
            "Current_q_value tensor(1.2123, grad_fn=<SelectBackward0>)\n",
            "actions:  125\n",
            "Current_q_value tensor(1.3815, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(2.2467, grad_fn=<SelectBackward0>)\n",
            "Episode 63, Total Reward: 985.4847784113863\n",
            "actions:  107\n",
            "Current_q_value tensor(13.3657, grad_fn=<SelectBackward0>)\n",
            "actions:  22\n",
            "Current_q_value tensor(-0.0034, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.1868, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.4205, grad_fn=<SelectBackward0>)\n",
            "actions:  15\n",
            "Current_q_value tensor(0.3916, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.8692, grad_fn=<SelectBackward0>)\n",
            "actions:  51\n",
            "Current_q_value tensor(2.2559, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(3.8818, grad_fn=<SelectBackward0>)\n",
            "actions:  114\n",
            "Current_q_value tensor(2.1605, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(3.9106, grad_fn=<SelectBackward0>)\n",
            "actions:  97\n",
            "Current_q_value tensor(-0.2461, grad_fn=<SelectBackward0>)\n",
            "actions:  58\n",
            "Current_q_value tensor(-0.0219, grad_fn=<SelectBackward0>)\n",
            "actions:  15\n",
            "Current_q_value tensor(0.7101, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.0620, grad_fn=<SelectBackward0>)\n",
            "actions:  95\n",
            "Current_q_value tensor(2.2302, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.8351, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.0470, grad_fn=<SelectBackward0>)\n",
            "actions:  8\n",
            "Current_q_value tensor(1.7934, grad_fn=<SelectBackward0>)\n",
            "actions:  84\n",
            "Current_q_value tensor(1.7746, grad_fn=<SelectBackward0>)\n",
            "actions:  80\n",
            "Current_q_value tensor(1.5194, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.8144, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.9657, grad_fn=<SelectBackward0>)\n",
            "actions:  15\n",
            "Current_q_value tensor(1.1720, grad_fn=<SelectBackward0>)\n",
            "actions:  4\n",
            "Current_q_value tensor(2.7202, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.6867, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(4.6757, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(18.2879, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(4.2839, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(4.3240, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(2.1312, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(4.3616, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.3896, grad_fn=<SelectBackward0>)\n",
            "actions:  32\n",
            "Current_q_value tensor(0.8832, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.0821, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(2.7148, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.6435, grad_fn=<SelectBackward0>)\n",
            "actions:  71\n",
            "Current_q_value tensor(0.8058, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(5.8977, grad_fn=<SelectBackward0>)\n",
            "actions:  61\n",
            "Current_q_value tensor(3.2952, grad_fn=<SelectBackward0>)\n",
            "Episode 64, Total Reward: -635.5442924087984\n",
            "actions:  58\n",
            "Current_q_value tensor(0.5822, grad_fn=<SelectBackward0>)\n",
            "actions:  74\n",
            "Current_q_value tensor(1.2197, grad_fn=<SelectBackward0>)\n",
            "actions:  87\n",
            "Current_q_value tensor(2.6372, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(13.6194, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(-0.1885, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(1.3640, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.2416, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(4.5658, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.2668, grad_fn=<SelectBackward0>)\n",
            "actions:  59\n",
            "Current_q_value tensor(1.7900, grad_fn=<SelectBackward0>)\n",
            "Episode 65, Total Reward: 2061.9320366803695\n",
            "actions:  24\n",
            "Current_q_value tensor(2.9316, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(14.4035, grad_fn=<SelectBackward0>)\n",
            "actions:  114\n",
            "Current_q_value tensor(1.9858, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(0.7842, grad_fn=<SelectBackward0>)\n",
            "actions:  89\n",
            "Current_q_value tensor(0.6484, grad_fn=<SelectBackward0>)\n",
            "Episode 66, Total Reward: 931.5683537616133\n",
            "actions:  107\n",
            "Current_q_value tensor(14.8769, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.7070, grad_fn=<SelectBackward0>)\n",
            "actions:  104\n",
            "Current_q_value tensor(0.8369, grad_fn=<SelectBackward0>)\n",
            "actions:  79\n",
            "Current_q_value tensor(1.1328, grad_fn=<SelectBackward0>)\n",
            "actions:  14\n",
            "Current_q_value tensor(1.0211, grad_fn=<SelectBackward0>)\n",
            "actions:  106\n",
            "Current_q_value tensor(-0.8407, grad_fn=<SelectBackward0>)\n",
            "actions:  6\n",
            "Current_q_value tensor(2.9019, grad_fn=<SelectBackward0>)\n",
            "actions:  69\n",
            "Current_q_value tensor(0.1648, grad_fn=<SelectBackward0>)\n",
            "actions:  90\n",
            "Current_q_value tensor(3.7691, grad_fn=<SelectBackward0>)\n",
            "actions:  31\n",
            "Current_q_value tensor(2.0051, grad_fn=<SelectBackward0>)\n",
            "actions:  95\n",
            "Current_q_value tensor(5.1613, grad_fn=<SelectBackward0>)\n",
            "actions:  29\n",
            "Current_q_value tensor(3.0529, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(21.6646, grad_fn=<SelectBackward0>)\n",
            "actions:  32\n",
            "Current_q_value tensor(1.8384, grad_fn=<SelectBackward0>)\n",
            "actions:  17\n",
            "Current_q_value tensor(-1.0103, grad_fn=<SelectBackward0>)\n",
            "actions:  66\n",
            "Current_q_value tensor(4.2147, grad_fn=<SelectBackward0>)\n",
            "actions:  6\n",
            "Current_q_value tensor(2.5179, grad_fn=<SelectBackward0>)\n",
            "actions:  6\n",
            "Current_q_value tensor(2.6970, grad_fn=<SelectBackward0>)\n",
            "actions:  81\n",
            "Current_q_value tensor(-0.8059, grad_fn=<SelectBackward0>)\n",
            "actions:  86\n",
            "Current_q_value tensor(2.1914, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(11.3831, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(28.5485, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(6.0851, grad_fn=<SelectBackward0>)\n",
            "actions:  44\n",
            "Current_q_value tensor(2.8278, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(10.4230, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(29.0986, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(3.4527, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(9.2799, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(29.0341, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(6.1142, grad_fn=<SelectBackward0>)\n",
            "actions:  75\n",
            "Current_q_value tensor(0.4438, grad_fn=<SelectBackward0>)\n",
            "actions:  84\n",
            "Current_q_value tensor(5.1935, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(9.6692, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(31.0673, grad_fn=<SelectBackward0>)\n",
            "actions:  121\n",
            "Current_q_value tensor(4.9546, grad_fn=<SelectBackward0>)\n",
            "Episode 67, Total Reward: 1423.1831910319324\n",
            "actions:  107\n",
            "Current_q_value tensor(17.3866, grad_fn=<SelectBackward0>)\n",
            "actions:  45\n",
            "Current_q_value tensor(1.9899, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.0721, grad_fn=<SelectBackward0>)\n",
            "actions:  124\n",
            "Current_q_value tensor(1.0823, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.7657, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.1817, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(5.8321, grad_fn=<SelectBackward0>)\n",
            "actions:  118\n",
            "Current_q_value tensor(2.0887, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.1384, grad_fn=<SelectBackward0>)\n",
            "actions:  2\n",
            "Current_q_value tensor(2.7645, grad_fn=<SelectBackward0>)\n",
            "actions:  5\n",
            "Current_q_value tensor(0.0501, grad_fn=<SelectBackward0>)\n",
            "actions:  98\n",
            "Current_q_value tensor(-1.2481, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(2.4763, grad_fn=<SelectBackward0>)\n",
            "actions:  52\n",
            "Current_q_value tensor(0.1159, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.3950, grad_fn=<SelectBackward0>)\n",
            "actions:  29\n",
            "Current_q_value tensor(1.2271, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(4.6749, grad_fn=<SelectBackward0>)\n",
            "Episode 68, Total Reward: 284.2640528991251\n",
            "actions:  107\n",
            "Current_q_value tensor(18.2161, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(2.3797, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(0.7747, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.0965, grad_fn=<SelectBackward0>)\n",
            "actions:  0\n",
            "Current_q_value tensor(0.1203, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.0444, grad_fn=<SelectBackward0>)\n",
            "actions:  79\n",
            "Current_q_value tensor(1.6474, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.0890, grad_fn=<SelectBackward0>)\n",
            "actions:  3\n",
            "Current_q_value tensor(-0.8382, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.0354, grad_fn=<SelectBackward0>)\n",
            "actions:  106\n",
            "Current_q_value tensor(-2.2659, grad_fn=<SelectBackward0>)\n",
            "actions:  79\n",
            "Current_q_value tensor(4.7347, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(17.6024, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.6779, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.5215, grad_fn=<SelectBackward0>)\n",
            "actions:  43\n",
            "Current_q_value tensor(0.5645, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.0104, grad_fn=<SelectBackward0>)\n",
            "actions:  102\n",
            "Current_q_value tensor(3.2195, grad_fn=<SelectBackward0>)\n",
            "actions:  30\n",
            "Current_q_value tensor(3.7360, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.5805, grad_fn=<SelectBackward0>)\n",
            "actions:  116\n",
            "Current_q_value tensor(2.3699, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.1079, grad_fn=<SelectBackward0>)\n",
            "actions:  76\n",
            "Current_q_value tensor(1.3077, grad_fn=<SelectBackward0>)\n",
            "actions:  24\n",
            "Current_q_value tensor(1.8269, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.5367, grad_fn=<SelectBackward0>)\n",
            "actions:  28\n",
            "Current_q_value tensor(2.4136, grad_fn=<SelectBackward0>)\n",
            "actions:  101\n",
            "Current_q_value tensor(1.8868, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.6191, grad_fn=<SelectBackward0>)\n",
            "actions:  90\n",
            "Current_q_value tensor(3.0700, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.5702, grad_fn=<SelectBackward0>)\n",
            "actions:  75\n",
            "Current_q_value tensor(1.8488, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(2.0938, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.2702, grad_fn=<SelectBackward0>)\n",
            "actions:  42\n",
            "Current_q_value tensor(2.6060, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.6613, grad_fn=<SelectBackward0>)\n",
            "actions:  36\n",
            "Current_q_value tensor(-0.1714, grad_fn=<SelectBackward0>)\n",
            "actions:  71\n",
            "Current_q_value tensor(2.0136, grad_fn=<SelectBackward0>)\n",
            "actions:  53\n",
            "Current_q_value tensor(1.3436, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.1558, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.8761, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.0627, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.8417, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.9835, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.8233, grad_fn=<SelectBackward0>)\n",
            "actions:  118\n",
            "Current_q_value tensor(3.6414, grad_fn=<SelectBackward0>)\n",
            "actions:  61\n",
            "Current_q_value tensor(2.3467, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.2919, grad_fn=<SelectBackward0>)\n",
            "actions:  19\n",
            "Current_q_value tensor(3.3068, grad_fn=<SelectBackward0>)\n",
            "Episode 69, Total Reward: 1014.8064032881994\n",
            "actions:  44\n",
            "Current_q_value tensor(3.6449, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(19.3583, grad_fn=<SelectBackward0>)\n",
            "actions:  94\n",
            "Current_q_value tensor(1.6125, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(1.3017, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.8214, grad_fn=<SelectBackward0>)\n",
            "actions:  116\n",
            "Current_q_value tensor(2.8436, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.1812, grad_fn=<SelectBackward0>)\n",
            "actions:  113\n",
            "Current_q_value tensor(0.6477, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.4017, grad_fn=<SelectBackward0>)\n",
            "actions:  31\n",
            "Current_q_value tensor(1.1956, grad_fn=<SelectBackward0>)\n",
            "actions:  5\n",
            "Current_q_value tensor(1.0304, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.8977, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.8660, grad_fn=<SelectBackward0>)\n",
            "actions:  14\n",
            "Current_q_value tensor(2.3700, grad_fn=<SelectBackward0>)\n",
            "actions:  114\n",
            "Current_q_value tensor(4.3718, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(3.3249, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.0359, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.0631, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(2.0259, grad_fn=<SelectBackward0>)\n",
            "Episode 70, Total Reward: 1249.618407039079\n",
            "actions:  94\n",
            "Current_q_value tensor(5.2920, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(20.3453, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.0146, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.3313, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(2.0169, grad_fn=<SelectBackward0>)\n",
            "actions:  32\n",
            "Current_q_value tensor(1.9739, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.0940, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(2.6022, grad_fn=<SelectBackward0>)\n",
            "actions:  9\n",
            "Current_q_value tensor(-1.5064, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.7438, grad_fn=<SelectBackward0>)\n",
            "actions:  53\n",
            "Current_q_value tensor(1.6944, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.4128, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(5.0111, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.4165, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.4867, grad_fn=<SelectBackward0>)\n",
            "actions:  62\n",
            "Current_q_value tensor(0.9976, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.3965, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.5532, grad_fn=<SelectBackward0>)\n",
            "actions:  1\n",
            "Current_q_value tensor(3.3360, grad_fn=<SelectBackward0>)\n",
            "Episode 71, Total Reward: 1003.1755071500211\n",
            "actions:  111\n",
            "Current_q_value tensor(3.3088, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(3.2301, grad_fn=<SelectBackward0>)\n",
            "actions:  78\n",
            "Current_q_value tensor(2.7530, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(21.5036, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.3510, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.3957, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.4019, grad_fn=<SelectBackward0>)\n",
            "actions:  121\n",
            "Current_q_value tensor(2.4432, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.2479, grad_fn=<SelectBackward0>)\n",
            "actions:  73\n",
            "Current_q_value tensor(2.2347, grad_fn=<SelectBackward0>)\n",
            "Episode 72, Total Reward: 2053.1370695102178\n",
            "actions:  107\n",
            "Current_q_value tensor(22.2299, grad_fn=<SelectBackward0>)\n",
            "actions:  42\n",
            "Current_q_value tensor(2.4124, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.5548, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.4654, grad_fn=<SelectBackward0>)\n",
            "actions:  6\n",
            "Current_q_value tensor(1.6076, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.6119, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(2.9647, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.4861, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.6698, grad_fn=<SelectBackward0>)\n",
            "actions:  94\n",
            "Current_q_value tensor(3.3150, grad_fn=<SelectBackward0>)\n",
            "actions:  32\n",
            "Current_q_value tensor(2.5439, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(3.7346, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.8645, grad_fn=<SelectBackward0>)\n",
            "actions:  94\n",
            "Current_q_value tensor(4.0620, grad_fn=<SelectBackward0>)\n",
            "actions:  45\n",
            "Current_q_value tensor(3.6543, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.7061, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.1825, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.6694, grad_fn=<SelectBackward0>)\n",
            "actions:  36\n",
            "Current_q_value tensor(0.9561, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.1527, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.6006, grad_fn=<SelectBackward0>)\n",
            "actions:  0\n",
            "Current_q_value tensor(1.1127, grad_fn=<SelectBackward0>)\n",
            "actions:  83\n",
            "Current_q_value tensor(2.1904, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.3343, grad_fn=<SelectBackward0>)\n",
            "actions:  40\n",
            "Current_q_value tensor(2.2455, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.7514, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(-0.8411, grad_fn=<SelectBackward0>)\n",
            "actions:  93\n",
            "Current_q_value tensor(1.5612, grad_fn=<SelectBackward0>)\n",
            "Episode 73, Total Reward: 200.8248561875116\n",
            "actions:  107\n",
            "Current_q_value tensor(22.9797, grad_fn=<SelectBackward0>)\n",
            "actions:  66\n",
            "Current_q_value tensor(3.2289, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.8143, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.4106, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.8283, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.4017, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.8429, grad_fn=<SelectBackward0>)\n",
            "actions:  34\n",
            "Current_q_value tensor(2.9345, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.3899, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.8718, grad_fn=<SelectBackward0>)\n",
            "actions:  121\n",
            "Current_q_value tensor(3.5219, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(3.3718, grad_fn=<SelectBackward0>)\n",
            "Episode 74, Total Reward: 1264.1966671484515\n",
            "actions:  107\n",
            "Current_q_value tensor(23.0548, grad_fn=<SelectBackward0>)\n",
            "actions:  3\n",
            "Current_q_value tensor(0.2085, grad_fn=<SelectBackward0>)\n",
            "actions:  124\n",
            "Current_q_value tensor(2.1931, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.1299, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.5471, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.1928, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.5827, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.2488, grad_fn=<SelectBackward0>)\n",
            "actions:  44\n",
            "Current_q_value tensor(3.3286, grad_fn=<SelectBackward0>)\n",
            "actions:  25\n",
            "Current_q_value tensor(2.9682, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.3062, grad_fn=<SelectBackward0>)\n",
            "actions:  24\n",
            "Current_q_value tensor(3.7533, grad_fn=<SelectBackward0>)\n",
            "actions:  93\n",
            "Current_q_value tensor(2.1666, grad_fn=<SelectBackward0>)\n",
            "Episode 75, Total Reward: 70.43001906086647\n",
            "actions:  107\n",
            "Current_q_value tensor(23.1731, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(3.8541, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(-0.3045, grad_fn=<SelectBackward0>)\n",
            "actions:  46\n",
            "Current_q_value tensor(2.9511, grad_fn=<SelectBackward0>)\n",
            "actions:  88\n",
            "Current_q_value tensor(1.4881, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.3608, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.6860, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.3976, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.7021, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.4314, grad_fn=<SelectBackward0>)\n",
            "actions:  31\n",
            "Current_q_value tensor(2.1308, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(6.8041, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(6.8084, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(6.8096, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(6.8081, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(3.8250, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.8470, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(6.4062, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(4.9835, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.8167, grad_fn=<SelectBackward0>)\n",
            "actions:  5\n",
            "Current_q_value tensor(1.4773, grad_fn=<SelectBackward0>)\n",
            "actions:  37\n",
            "Current_q_value tensor(2.6504, grad_fn=<SelectBackward0>)\n",
            "Episode 76, Total Reward: 344.7625048668051\n",
            "actions:  107\n",
            "Current_q_value tensor(23.1790, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.6438, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.8083, grad_fn=<SelectBackward0>)\n",
            "actions:  19\n",
            "Current_q_value tensor(3.1851, grad_fn=<SelectBackward0>)\n",
            "Episode 77, Total Reward: 0.0\n",
            "actions:  107\n",
            "Current_q_value tensor(23.1767, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.7089, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(2.3846, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.9570, grad_fn=<SelectBackward0>)\n",
            "actions:  104\n",
            "Current_q_value tensor(2.5466, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.9436, grad_fn=<SelectBackward0>)\n",
            "actions:  70\n",
            "Current_q_value tensor(2.4384, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(3.6918, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(6.9283, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.8618, grad_fn=<SelectBackward0>)\n",
            "actions:  121\n",
            "Current_q_value tensor(4.8538, grad_fn=<SelectBackward0>)\n",
            "Episode 78, Total Reward: 142.62795139984883\n",
            "actions:  107\n",
            "Current_q_value tensor(23.1674, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-1.9090, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.1663, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.2916, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.2550, grad_fn=<SelectBackward0>)\n",
            "actions:  29\n",
            "Current_q_value tensor(2.1928, grad_fn=<SelectBackward0>)\n",
            "actions:  40\n",
            "Current_q_value tensor(3.0710, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.6216, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.6088, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.6251, grad_fn=<SelectBackward0>)\n",
            "actions:  102\n",
            "Current_q_value tensor(4.5056, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(4.2991, grad_fn=<SelectBackward0>)\n",
            "actions:  84\n",
            "Current_q_value tensor(4.8293, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.6865, grad_fn=<SelectBackward0>)\n",
            "actions:  41\n",
            "Current_q_value tensor(-1.8320, grad_fn=<SelectBackward0>)\n",
            "actions:  102\n",
            "Current_q_value tensor(5.6608, grad_fn=<SelectBackward0>)\n",
            "actions:  43\n",
            "Current_q_value tensor(2.5106, grad_fn=<SelectBackward0>)\n",
            "actions:  31\n",
            "Current_q_value tensor(4.1158, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(10.6715, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(36.8668, grad_fn=<SelectBackward0>)\n",
            "actions:  3\n",
            "Current_q_value tensor(0.7239, grad_fn=<SelectBackward0>)\n",
            "actions:  63\n",
            "Current_q_value tensor(2.4092, grad_fn=<SelectBackward0>)\n",
            "Episode 79, Total Reward: 382.9537741320546\n",
            "actions:  107\n",
            "Current_q_value tensor(23.1552, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.5075, grad_fn=<SelectBackward0>)\n",
            "actions:  13\n",
            "Current_q_value tensor(-0.6251, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.0249, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.0999, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(7.0904, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.1780, grad_fn=<SelectBackward0>)\n",
            "actions:  67\n",
            "Current_q_value tensor(0.9207, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.3672, grad_fn=<SelectBackward0>)\n",
            "actions:  27\n",
            "Current_q_value tensor(0.9270, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.5638, grad_fn=<SelectBackward0>)\n",
            "actions:  80\n",
            "Current_q_value tensor(3.5905, grad_fn=<SelectBackward0>)\n",
            "actions:  55\n",
            "Current_q_value tensor(3.2263, grad_fn=<SelectBackward0>)\n",
            "Episode 80, Total Reward: 558.3535390269735\n",
            "actions:  48\n",
            "Current_q_value tensor(8.4651, grad_fn=<SelectBackward0>)\n",
            "actions:  75\n",
            "Current_q_value tensor(-0.0663, grad_fn=<SelectBackward0>)\n",
            "actions:  59\n",
            "Current_q_value tensor(4.9685, grad_fn=<SelectBackward0>)\n",
            "actions:  120\n",
            "Current_q_value tensor(4.1545, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(26.2113, grad_fn=<SelectBackward0>)\n",
            "actions:  8\n",
            "Current_q_value tensor(3.1491, grad_fn=<SelectBackward0>)\n",
            "actions:  81\n",
            "Current_q_value tensor(0.2178, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(6.6051, grad_fn=<SelectBackward0>)\n",
            "actions:  49\n",
            "Current_q_value tensor(0.1507, grad_fn=<SelectBackward0>)\n",
            "actions:  89\n",
            "Current_q_value tensor(2.0068, grad_fn=<SelectBackward0>)\n",
            "Episode 81, Total Reward: 1171.230262720257\n",
            "actions:  22\n",
            "Current_q_value tensor(2.4119, grad_fn=<SelectBackward0>)\n",
            "actions:  24\n",
            "Current_q_value tensor(4.4157, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(23.5669, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.2409, grad_fn=<SelectBackward0>)\n",
            "actions:  29\n",
            "Current_q_value tensor(2.3673, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.5203, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.7433, grad_fn=<SelectBackward0>)\n",
            "actions:  70\n",
            "Current_q_value tensor(3.8047, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.5140, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.7737, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.4933, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.7874, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.4699, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.8071, grad_fn=<SelectBackward0>)\n",
            "actions:  20\n",
            "Current_q_value tensor(1.2881, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.4498, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(7.7390, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.8462, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.3955, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.8672, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.0558, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.1235, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.6587, grad_fn=<SelectBackward0>)\n",
            "actions:  84\n",
            "Current_q_value tensor(5.8216, grad_fn=<SelectBackward0>)\n",
            "actions:  17\n",
            "Current_q_value tensor(-0.0916, grad_fn=<SelectBackward0>)\n",
            "actions:  125\n",
            "Current_q_value tensor(3.3903, grad_fn=<SelectBackward0>)\n",
            "actions:  8\n",
            "Current_q_value tensor(5.2483, grad_fn=<SelectBackward0>)\n",
            "actions:  78\n",
            "Current_q_value tensor(3.2724, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(10.8731, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(10.9617, grad_fn=<SelectBackward0>)\n",
            "actions:  98\n",
            "Current_q_value tensor(-1.5476, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(11.0735, grad_fn=<SelectBackward0>)\n",
            "actions:  112\n",
            "Current_q_value tensor(3.3995, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(11.1540, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(11.1975, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(6.5573, grad_fn=<SelectBackward0>)\n",
            "actions:  35\n",
            "Current_q_value tensor(0.4932, grad_fn=<SelectBackward0>)\n",
            "actions:  90\n",
            "Current_q_value tensor(5.3915, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(11.9423, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(12.0082, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(12.0636, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(12.1105, grad_fn=<SelectBackward0>)\n",
            "actions:  24\n",
            "Current_q_value tensor(3.1431, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(5.9237, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(12.2867, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(12.3526, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(5.5331, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(34.4316, grad_fn=<SelectBackward0>)\n",
            "actions:  79\n",
            "Current_q_value tensor(4.6794, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(13.5175, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(13.6000, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(8.9198, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(13.7362, grad_fn=<SelectBackward0>)\n",
            "actions:  28\n",
            "Current_q_value tensor(5.9918, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(8.0807, grad_fn=<SelectBackward0>)\n",
            "actions:  116\n",
            "Current_q_value tensor(6.9881, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(13.1055, grad_fn=<SelectBackward0>)\n",
            "actions:  96\n",
            "Current_q_value tensor(1.6772, grad_fn=<SelectBackward0>)\n",
            "actions:  126\n",
            "Current_q_value tensor(7.5896, grad_fn=<SelectBackward0>)\n",
            "actions:  88\n",
            "Current_q_value tensor(4.6858, grad_fn=<SelectBackward0>)\n",
            "actions:  125\n",
            "Current_q_value tensor(5.9287, grad_fn=<SelectBackward0>)\n",
            "actions:  109\n",
            "Current_q_value tensor(2.3111, grad_fn=<SelectBackward0>)\n",
            "Episode 82, Total Reward: 2176.663236614946\n",
            "actions:  107\n",
            "Current_q_value tensor(26.0159, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(0.4043, grad_fn=<SelectBackward0>)\n",
            "actions:  65\n",
            "Current_q_value tensor(-2.3301, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(14.3558, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.5587, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(14.4252, grad_fn=<SelectBackward0>)\n",
            "actions:  43\n",
            "Current_q_value tensor(3.3768, grad_fn=<SelectBackward0>)\n",
            "actions:  82\n",
            "Current_q_value tensor(8.7390, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.0718, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(15.1828, grad_fn=<SelectBackward0>)\n",
            "actions:  24\n",
            "Current_q_value tensor(2.7480, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.0953, grad_fn=<SelectBackward0>)\n",
            "actions:  63\n",
            "Current_q_value tensor(3.7642, grad_fn=<SelectBackward0>)\n",
            "actions:  67\n",
            "Current_q_value tensor(2.6259, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(9.1049, grad_fn=<SelectBackward0>)\n",
            "actions:  124\n",
            "Current_q_value tensor(5.5585, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(16.6945, grad_fn=<SelectBackward0>)\n",
            "Episode 83, Total Reward: 533.767543562255\n",
            "actions:  107\n",
            "Current_q_value tensor(26.1780, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.2890, grad_fn=<SelectBackward0>)\n",
            "actions:  9\n",
            "Current_q_value tensor(-1.2136, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(8.6844, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(8.6893, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(8.6924, grad_fn=<SelectBackward0>)\n",
            "actions:  28\n",
            "Current_q_value tensor(2.6373, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(8.6968, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(4.0221, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(9.2131, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(9.2193, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(9.2234, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(-0.3267, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(9.2282, grad_fn=<SelectBackward0>)\n",
            "actions:  53\n",
            "Current_q_value tensor(1.9504, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(9.9813, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(9.9802, grad_fn=<SelectBackward0>)\n",
            "actions:  14\n",
            "Current_q_value tensor(4.4644, grad_fn=<SelectBackward0>)\n",
            "actions:  93\n",
            "Current_q_value tensor(3.6592, grad_fn=<SelectBackward0>)\n",
            "Episode 84, Total Reward: 78.4821952760085\n",
            "actions:  30\n",
            "Current_q_value tensor(5.5605, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(0.4239, grad_fn=<SelectBackward0>)\n",
            "actions:  38\n",
            "Current_q_value tensor(0.8927, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(26.2055, grad_fn=<SelectBackward0>)\n",
            "actions:  96\n",
            "Current_q_value tensor(1.5645, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.5497, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.5497, grad_fn=<SelectBackward0>)\n",
            "actions:  58\n",
            "Current_q_value tensor(1.8659, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.5745, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.5164, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.5989, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-1.3043, grad_fn=<SelectBackward0>)\n",
            "actions:  39\n",
            "Current_q_value tensor(1.3709, grad_fn=<SelectBackward0>)\n",
            "actions:  54\n",
            "Current_q_value tensor(6.3572, grad_fn=<SelectBackward0>)\n",
            "actions:  120\n",
            "Current_q_value tensor(6.0061, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.5934, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(14.9129, grad_fn=<SelectBackward0>)\n",
            "actions:  65\n",
            "Current_q_value tensor(-1.2685, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(8.0572, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.8732, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(16.1701, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.8157, grad_fn=<SelectBackward0>)\n",
            "actions:  41\n",
            "Current_q_value tensor(-0.7880, grad_fn=<SelectBackward0>)\n",
            "actions:  125\n",
            "Current_q_value tensor(3.6375, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(18.0485, grad_fn=<SelectBackward0>)\n",
            "actions:  46\n",
            "Current_q_value tensor(8.0372, grad_fn=<SelectBackward0>)\n",
            "actions:  44\n",
            "Current_q_value tensor(6.9478, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(13.6387, grad_fn=<SelectBackward0>)\n",
            "actions:  0\n",
            "Current_q_value tensor(3.6985, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(18.1805, grad_fn=<SelectBackward0>)\n",
            "actions:  23\n",
            "Current_q_value tensor(0.6709, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(14.2860, grad_fn=<SelectBackward0>)\n",
            "actions:  14\n",
            "Current_q_value tensor(8.0705, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(8.8427, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(8.1761, grad_fn=<SelectBackward0>)\n",
            "Episode 85, Total Reward: 1114.6142900951472\n",
            "actions:  107\n",
            "Current_q_value tensor(27.8049, grad_fn=<SelectBackward0>)\n",
            "actions:  84\n",
            "Current_q_value tensor(5.7802, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(4.7779, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(13.2774, grad_fn=<SelectBackward0>)\n",
            "actions:  13\n",
            "Current_q_value tensor(0.3941, grad_fn=<SelectBackward0>)\n",
            "actions:  20\n",
            "Current_q_value tensor(2.5245, grad_fn=<SelectBackward0>)\n",
            "actions:  45\n",
            "Current_q_value tensor(5.2340, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(9.6669, grad_fn=<SelectBackward0>)\n",
            "actions:  115\n",
            "Current_q_value tensor(4.5377, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(7.1914, grad_fn=<SelectBackward0>)\n",
            "actions:  9\n",
            "Current_q_value tensor(-0.5412, grad_fn=<SelectBackward0>)\n",
            "actions:  89\n",
            "Current_q_value tensor(4.3916, grad_fn=<SelectBackward0>)\n",
            "Episode 86, Total Reward: 395.4103760615708\n",
            "actions:  11\n",
            "Current_q_value tensor(-3.5585, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(28.0655, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(13.9642, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.4910, grad_fn=<SelectBackward0>)\n",
            "actions:  114\n",
            "Current_q_value tensor(5.9668, grad_fn=<SelectBackward0>)\n",
            "actions:  24\n",
            "Current_q_value tensor(2.1896, grad_fn=<SelectBackward0>)\n",
            "actions:  3\n",
            "Current_q_value tensor(2.2816, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(14.2932, grad_fn=<SelectBackward0>)\n",
            "actions:  44\n",
            "Current_q_value tensor(5.8044, grad_fn=<SelectBackward0>)\n",
            "actions:  66\n",
            "Current_q_value tensor(6.6754, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.6824, grad_fn=<SelectBackward0>)\n",
            "actions:  38\n",
            "Current_q_value tensor(3.0810, grad_fn=<SelectBackward0>)\n",
            "actions:  88\n",
            "Current_q_value tensor(4.9268, grad_fn=<SelectBackward0>)\n",
            "actions:  125\n",
            "Current_q_value tensor(4.4128, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(15.2253, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(11.5498, grad_fn=<SelectBackward0>)\n",
            "actions:  95\n",
            "Current_q_value tensor(7.2773, grad_fn=<SelectBackward0>)\n",
            "Episode 87, Total Reward: 1058.994407586797\n",
            "actions:  63\n",
            "Current_q_value tensor(5.2657, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(10.5315, grad_fn=<SelectBackward0>)\n",
            "Episode 88, Total Reward: 0.0\n",
            "actions:  114\n",
            "Current_q_value tensor(9.7257, grad_fn=<SelectBackward0>)\n",
            "actions:  64\n",
            "Current_q_value tensor(2.9884, grad_fn=<SelectBackward0>)\n",
            "actions:  85\n",
            "Current_q_value tensor(3.9980, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(29.5405, grad_fn=<SelectBackward0>)\n",
            "actions:  76\n",
            "Current_q_value tensor(3.0312, grad_fn=<SelectBackward0>)\n",
            "actions:  60\n",
            "Current_q_value tensor(-0.2520, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(13.3261, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(8.6263, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(13.3924, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(8.7310, grad_fn=<SelectBackward0>)\n",
            "actions:  114\n",
            "Current_q_value tensor(7.5733, grad_fn=<SelectBackward0>)\n",
            "actions:  36\n",
            "Current_q_value tensor(2.1990, grad_fn=<SelectBackward0>)\n",
            "actions:  85\n",
            "Current_q_value tensor(3.5596, grad_fn=<SelectBackward0>)\n",
            "actions:  98\n",
            "Current_q_value tensor(-0.0981, grad_fn=<SelectBackward0>)\n",
            "actions:  63\n",
            "Current_q_value tensor(4.3652, grad_fn=<SelectBackward0>)\n",
            "Episode 89, Total Reward: 1009.9673176802862\n",
            "actions:  107\n",
            "Current_q_value tensor(30.7673, grad_fn=<SelectBackward0>)\n",
            "actions:  80\n",
            "Current_q_value tensor(4.4950, grad_fn=<SelectBackward0>)\n",
            "actions:  99\n",
            "Current_q_value tensor(5.6673, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(15.5658, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(10.4026, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(15.6729, grad_fn=<SelectBackward0>)\n",
            "actions:  106\n",
            "Current_q_value tensor(-3.7168, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(37.3521, grad_fn=<SelectBackward0>)\n",
            "actions:  56\n",
            "Current_q_value tensor(8.3708, grad_fn=<SelectBackward0>)\n",
            "actions:  55\n",
            "Current_q_value tensor(5.0160, grad_fn=<SelectBackward0>)\n",
            "Episode 90, Total Reward: 143.49920722848583\n",
            "actions:  107\n",
            "Current_q_value tensor(31.6391, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(14.3390, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(5.2312, grad_fn=<SelectBackward0>)\n",
            "actions:  14\n",
            "Current_q_value tensor(5.8846, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(9.6317, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(14.6618, grad_fn=<SelectBackward0>)\n",
            "actions:  55\n",
            "Current_q_value tensor(4.7178, grad_fn=<SelectBackward0>)\n",
            "Episode 91, Total Reward: 139.1904304560485\n",
            "actions:  2\n",
            "Current_q_value tensor(7.3883, grad_fn=<SelectBackward0>)\n",
            "actions:  122\n",
            "Current_q_value tensor(12.3835, grad_fn=<SelectBackward0>)\n",
            "actions:  17\n",
            "Current_q_value tensor(1.2323, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(34.0360, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(-1.1775, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(17.6356, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.2543, grad_fn=<SelectBackward0>)\n",
            "actions:  96\n",
            "Current_q_value tensor(4.0508, grad_fn=<SelectBackward0>)\n",
            "actions:  103\n",
            "Current_q_value tensor(5.7854, grad_fn=<SelectBackward0>)\n",
            "actions:  12\n",
            "Current_q_value tensor(10.3998, grad_fn=<SelectBackward0>)\n",
            "actions:  33\n",
            "Current_q_value tensor(-1.6262, grad_fn=<SelectBackward0>)\n",
            "actions:  36\n",
            "Current_q_value tensor(4.9313, grad_fn=<SelectBackward0>)\n",
            "actions:  104\n",
            "Current_q_value tensor(6.5907, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(8.7644, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(18.9515, grad_fn=<SelectBackward0>)\n",
            "actions:  44\n",
            "Current_q_value tensor(9.2002, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(14.2338, grad_fn=<SelectBackward0>)\n",
            "actions:  38\n",
            "Current_q_value tensor(5.0637, grad_fn=<SelectBackward0>)\n",
            "actions:  89\n",
            "Current_q_value tensor(6.7710, grad_fn=<SelectBackward0>)\n",
            "actions:  125\n",
            "Current_q_value tensor(8.1491, grad_fn=<SelectBackward0>)\n",
            "Episode 92, Total Reward: 1792.4959196010823\n",
            "actions:  82\n",
            "Current_q_value tensor(9.7860, grad_fn=<SelectBackward0>)\n",
            "actions:  27\n",
            "Current_q_value tensor(4.4656, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(37.6437, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(16.4841, grad_fn=<SelectBackward0>)\n",
            "actions:  7\n",
            "Current_q_value tensor(0.1630, grad_fn=<SelectBackward0>)\n",
            "actions:  49\n",
            "Current_q_value tensor(2.5691, grad_fn=<SelectBackward0>)\n",
            "Episode 93, Total Reward: 1034.7556960098136\n",
            "actions:  5\n",
            "Current_q_value tensor(3.1275, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(36.4856, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(16.7292, grad_fn=<SelectBackward0>)\n",
            "actions:  20\n",
            "Current_q_value tensor(4.4396, grad_fn=<SelectBackward0>)\n",
            "actions:  40\n",
            "Current_q_value tensor(5.2117, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.4639, grad_fn=<SelectBackward0>)\n",
            "actions:  111\n",
            "Current_q_value tensor(8.1743, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(17.0960, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(11.7197, grad_fn=<SelectBackward0>)\n",
            "actions:  93\n",
            "Current_q_value tensor(6.0754, grad_fn=<SelectBackward0>)\n",
            "Episode 94, Total Reward: 985.4847784113881\n",
            "actions:  38\n",
            "Current_q_value tensor(4.2159, grad_fn=<SelectBackward0>)\n",
            "actions:  100\n",
            "Current_q_value tensor(14.4164, grad_fn=<SelectBackward0>)\n",
            "actions:  27\n",
            "Current_q_value tensor(6.6344, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(43.3644, grad_fn=<SelectBackward0>)\n",
            "actions:  20\n",
            "Current_q_value tensor(6.5679, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(17.1564, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(13.9275, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(3.1192, grad_fn=<SelectBackward0>)\n",
            "actions:  113\n",
            "Current_q_value tensor(1.2300, grad_fn=<SelectBackward0>)\n",
            "actions:  28\n",
            "Current_q_value tensor(3.2115, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(45.4251, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(17.5175, grad_fn=<SelectBackward0>)\n",
            "actions:  26\n",
            "Current_q_value tensor(4.8883, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(10.7762, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(10.8563, grad_fn=<SelectBackward0>)\n",
            "actions:  32\n",
            "Current_q_value tensor(5.1385, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(10.9908, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(9.5782, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(11.0969, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(11.1403, grad_fn=<SelectBackward0>)\n",
            "actions:  96\n",
            "Current_q_value tensor(5.2873, grad_fn=<SelectBackward0>)\n",
            "actions:  48\n",
            "Current_q_value tensor(11.2111, grad_fn=<SelectBackward0>)\n",
            "actions:  92\n",
            "Current_q_value tensor(3.0868, grad_fn=<SelectBackward0>)\n",
            "actions:  91\n",
            "Current_q_value tensor(8.7104, grad_fn=<SelectBackward0>)\n",
            "Episode 95, Total Reward: 1007.042816903022\n",
            "actions:  107\n",
            "Current_q_value tensor(41.4350, grad_fn=<SelectBackward0>)\n",
            "actions:  108\n",
            "Current_q_value tensor(9.7402, grad_fn=<SelectBackward0>)\n",
            "actions:  45\n",
            "Current_q_value tensor(7.5039, grad_fn=<SelectBackward0>)\n",
            "actions:  37\n",
            "Current_q_value tensor(5.7462, grad_fn=<SelectBackward0>)\n",
            "Episode 96, Total Reward: 92.91985426399879\n",
            "actions:  3\n",
            "Current_q_value tensor(4.0807, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(43.4976, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(17.7145, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.1356, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(17.8551, grad_fn=<SelectBackward0>)\n",
            "actions:  93\n",
            "Current_q_value tensor(7.5269, grad_fn=<SelectBackward0>)\n",
            "Episode 97, Total Reward: 1009.9673176802844\n",
            "actions:  107\n",
            "Current_q_value tensor(42.7165, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(17.4274, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(6.8014, grad_fn=<SelectBackward0>)\n",
            "actions:  64\n",
            "Current_q_value tensor(7.0042, grad_fn=<SelectBackward0>)\n",
            "actions:  105\n",
            "Current_q_value tensor(5.4235, grad_fn=<SelectBackward0>)\n",
            "actions:  107\n",
            "Current_q_value tensor(49.4004, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.7079, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(18.6123, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(12.8533, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(18.7469, grad_fn=<SelectBackward0>)\n",
            "actions:  72\n",
            "Current_q_value tensor(7.7164, grad_fn=<SelectBackward0>)\n",
            "actions:  118\n",
            "Current_q_value tensor(3.8054, grad_fn=<SelectBackward0>)\n",
            "actions:  119\n",
            "Current_q_value tensor(18.9878, grad_fn=<SelectBackward0>)\n",
            "actions:  77\n",
            "Current_q_value tensor(9.8217, grad_fn=<SelectBackward0>)\n",
            "Episode 98, Total Reward: 85.27400580627545\n",
            "actions:  73\n",
            "Current_q_value tensor(8.3211, grad_fn=<SelectBackward0>)\n",
            "Episode 99, Total Reward: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.best_state, env.min_bic)\n",
        "print(calculate_bic_score(env.best_state, base_estimate))"
      ],
      "metadata": {
        "id": "Pmm8bEoHQ4DE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc45a73-2cf9-4798-cdd9-e48920f10a5c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 1 0 1 0 0 0 1]\n",
            " [0 0 0 0 1 1 0 0]\n",
            " [0 1 0 1 1 0 0 0]] 11401.946490471273\n",
            "-11401.946490471273\n"
          ]
        }
      ]
    }
  ]
}